# Configuration for Family Assistant

# LLM provider-specific parameters
# Keys can be full model names or prefixes (ending with '-')
# Parameters defined here will be passed as keyword arguments to litellm.completion
# for matching models.
llm_parameters:
  # Example for Gemini models via OpenRouter
  "openrouter/google/gemini-":
    reasoning: # Nest OpenRouter-specific reasoning params here
      effort: medium
    # Other top-level parameters for this model could still go here
    # temperature: 0.8
  # Example for another model type
  # "anthropic/claude-3-":
  #   temperature: 0.75
  #   top_k: 50

# Tools requiring explicit user confirmation before execution.
# Provide a list of tool names (strings).
# This list is overridden by the TOOLS_REQUIRING_CONFIRMATION environment variable if set.
tools_requiring_confirmation:
  - delete_calendar_event
  - modify_calendar_event
  # - tool_that_posts_online

# Configuration for the document indexing pipeline
indexing_pipeline_config:
  # Optional global configurations for the pipeline itself, if IndexingPipeline supports them
  # global_pipeline_config:
  #   some_global_setting: value

  processors:
    - type: "TitleExtractor"
      # config: {} # No specific config for TitleExtractor in this example
    - type: "PDFTextExtractor"
      # config: {} # No specific config for PDFTextExtractor
    - type: "WebFetcher"
      config: # Specific config for WebFetcherProcessor
        # Scraper instance is injected by DocumentIndexer, not configured here
        # Default user agent or other WebFetcherProcessor specific settings could go here
        # e.g. max_content_length: 1000000
        pass # No specific config other than scraper injection for now
    - type: "LLMSummaryGenerator"
      config:
        # llm_client is injected by DocumentIndexer
        input_content_types:
          - "original_document_file"
          - "raw_body_text" # For emails, if used by this indexer
          - "extracted_markdown_content" # From PDFTextExtractor
          - "fetched_content_markdown" # From WebFetcherProcessor
        target_embedding_type: "llm_generated_summary"
        # max_content_length: 100000 # Example, if needed
    - type: "TextChunker"
      config:
        chunk_size: 1000
        chunk_overlap: 100
        embedding_type_prefix_map:
          # For content parts directly provided to DocumentIndexer
          raw_body_text: "content_chunk"
          raw_file_text: "content_chunk"
          # For content generated by other processors
          extracted_markdown_content: "content_chunk" # From PDFTextExtractor
          fetched_content_markdown: "content_chunk" # From WebFetcherProcessor
    - type: "EmbeddingDispatch"
      config:
        embedding_types_to_dispatch:
          - "title"
          # - "summary" # If you have a manual summary type
          - "content_chunk"
          - "llm_generated_summary" # From LLMSummaryGeneratorProcessor

# Other future configurations can go here
# e.g., web_server_port: 8080
tools_requiring_confirmation:
  - delete_calendar_event
  - modify_calendar_event
  # - tool_that_posts_online

# Other future configurations can go here
# e.g., web_server_port: 8080
