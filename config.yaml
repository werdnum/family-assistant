# Configuration for Family Assistant
# LLM Provider Configuration
# Each service profile can specify a 'provider' in its processing_config.
# Available providers: 'litellm' (default), 'openai', 'google'
# - 'litellm': Uses LiteLLM for all models (supports many providers)
# - 'openai': Uses direct OpenAI SDK (requires OPENAI_API_KEY)
# - 'google': Uses direct Google GenAI SDK (requires GEMINI_API_KEY)
#
# Retry and Fallback Configuration (NEW):
# Use 'retry_config' format for automatic retry and fallback:
# processing_config:
#   retry_config:
#     primary:
#       provider: "openai"
#       model: "gpt-4o"
#     fallback:
#       provider: "google"
#       model: "gemini-2.5-pro"
# The system will retry once on the primary model for transient errors,
# then fall back to the fallback model if needed.
# Event system configuration
event_system:
  enabled: true
  storage:
    sample_interval_hours: 1.0 # Store 1 event per entity per hour
    max_event_size: 100000 # 100KB max event size
    retention_hours: 48
  sources:
    home_assistant:
      enabled: true
      # URL and token are shared with context provider
# LLM provider-specific parameters
# Keys can be full model names or prefixes (ending with '-')
# Parameters defined here will be passed as keyword arguments to litellm.completion
# for matching models.
llm_parameters:
  # Example for Gemini models via OpenRouter
  "openrouter/google/gemini-":
    reasoning: # Nest OpenRouter-specific reasoning params here
      effort: medium
      # Other top-level parameters for this model could still go here
      # temperature: 0.8
  # Example for another model type
  # "anthropic/claude-3-":
  #   temperature: 0.75
  #   top_k: 50
# Configuration for the document indexing pipeline
indexing_pipeline_config:
  # Optional global configurations for the pipeline itself, if IndexingPipeline supports them
  # global_pipeline_config:
  #   some_global_setting: value
  processors:
    - type: "TitleExtractor"
      # config: {} # No specific config for TitleExtractor in this example
    - type: "PDFTextExtractor"
      # config: {} # No specific config for PDFTextExtractor
    - type: "WebFetcher"
      config: {} # No specific config other than scraper injection for now
    - type: "LLMSummaryGenerator" # Specific config for WebFetcherProcessor
      config:
        # llm_client is injected by DocumentIndexer
        input_content_types:
          - "original_document_file"
          - "raw_body_text" # For emails, if used by this indexer
          - "extracted_markdown_content" # From PDFTextExtractor
          - "fetched_content_markdown" # From WebFetcherProcessor
        target_embedding_type: "llm_generated_summary"
        # max_content_length: 100000 # Example, if needed
    - type: "TextChunker"
      config:
        chunk_size: 1000
        chunk_overlap: 100
        embedding_type_prefix_map:
          # For content parts directly provided to DocumentIndexer
          raw_body_text: "content_chunk"
          raw_file_text: "content_chunk"
          raw_note_text: "content_chunk" # From NotesIndexer
          # For content generated by other processors
          extracted_markdown_content: "content_chunk" # From PDFTextExtractor
          fetched_content_markdown: "content_chunk" # From WebFetcherProcessor
    - type: "EmbeddingDispatch"
      config:
        embedding_types_to_dispatch:
          - "title"
          # - "summary" # If you have a manual summary type
          - "content_chunk"
          - "llm_generated_summary" # From LLMSummaryGeneratorProcessor
          # Raw content types - will be embedded if small enough, stored if too large
          - "raw_note_text"
          - "raw_body_text"
          - "raw_file_text"
          - "extracted_markdown_content" # Full PDF text
          - "fetched_content_markdown" # Full web page content
# Other future configurations can go here
# e.g., web_server_port: 8080

# --- Calendar Configuration ---
# Calendar configuration is shared across all profiles.
# Populated from environment variables (CALDAV_*, ICAL_URLS).
# Example calendar configuration:
# calendar_config:
#   caldav:
#     username: "user"
#     password: "password"
#     calendar_urls: ["url1"]
#   ical:
#     urls: ["url2"]
#   duplicate_detection:
#     enabled: true  # Enable duplicate event detection (default: true)
#     similarity_strategy: "fuzzy"  # Strategy: "fuzzy" (fast, zero dependencies) or "embedding" (requires local-embeddings extra)
#     similarity_threshold: 0.30  # Similarity threshold (0.0-1.0). Events above this are considered duplicates
#     time_window_hours: 2  # Time window in hours to search for duplicates around the event time

# --- Default Service Profile Configuration ---
# Settings for the primary, default assistant behavior.
default_profile_settings:
  processing_config:
    retry_config:
      primary:
        provider: "google"
        model: "gemini-2.5-pro"
      fallback:
        provider: "openai"
        model: "gpt-5"
    home_assistant_context_template: "{# Macro to format a distance value (assumed to be in km by the distance() function) \n   into a user-friendly string with 'm' or 'km'. #}\n{%- macro get_formatted_distance_string(distance_value_km) -%}\n  {%- if distance_value_km is number and distance_value_km < 1 -%}\n    {{- (distance_value_km * 1000) | round(0) ~ \" m\" -}}\n  {%- elif distance_value_km is number -%}\n    {{- distance_value_km | round(1) ~ \" km\" -}}\n  {%- else -%}\n    {{- \"\" -}} {# Handle cases where distance might not be a number #}\n  {%- endif -%}\n{%- endmacro -%}\n\n{# Macro to find the closest zone to a person and its distance.\n   It populates the 'out_ns.result_dict' with a dictionary \n   containing {'zone_obj': <state_obj>, 'distance': <float>}, or sets it to none. #}\n{%- macro find_closest_zone_data(person_obj, out_ns) -%}\n  {%- set zones_with_distances = namespace(list=[]) -%}\n\n  {%- for zone_obj in states.zone | rejectattr('entity_id', 'equalto', 'zone.near_home') -%}\n    {%- set current_dist = distance(zone_obj.entity_id, person_obj.entity_id) -%}\n    {%- if current_dist is number -%}\n      {%- set zones_with_distances.list = zones_with_distances.list + [{'zone_obj': zone_obj, 'distance': current_dist}] -%}\n    {%- endif -%}\n  {%- endfor -%}\n\n  {%- if zones_with_distances.list -%}\n    {%- set out_ns.result_dict = (zones_with_distances.list | sort(attribute='distance') | first) -%}\n  {%- else -%}\n    {%- set out_ns.result_dict = none -%}\n  {%- endif -%}\n  {# This macro modifies 'out_ns' by side effect and does not render its primary data as output. #}\n{%- endmacro -%}\n\n{# Macro to determine and return the detailed portion of a 'not_home' status message.\n   For example: \" 1.2 km from Work\" or \" (location data unavailable)\". #}\n{%- macro get_not_home_status_details(person_obj) -%}\n  {%- if state_attr(person_obj.entity_id, 'latitude') is not none and state_attr(person_obj.entity_id, 'longitude') is not none -%}\n    {%- if states.zone | length > 0 -%}\n      {# Create a namespace to hold the output from the find_closest_zone_data macro #}\n      {%- set closest_zone_ns = namespace(result_dict=none) -%}\n      {# Call the macro; it will populate closest_zone_ns.result_dict by side effect. #}\n      {# Assigning to '_' signifies we're primarily interested in the side effect, not the macro's direct string output (which should be empty). #}\n      {%- set _ = find_closest_zone_data(person_obj, closest_zone_ns) -%} \n      \n      {%- set closest_zone_data = closest_zone_ns.result_dict -%} {# Retrieve the actual dictionary #}\n\n      {%- if closest_zone_data is not none and closest_zone_data.distance is number -%}\n        {{- \" \" ~ get_formatted_distance_string(closest_zone_data.distance) ~ \" from \" ~ closest_zone_data.zone_obj.name -}}\n      {%- elif closest_zone_data is not none -%} {# A zone was found, but distance was invalid for formatting #}\n        {{- \" (could not calculate distance to \" ~ closest_zone_data.zone_obj.name ~ \")\" -}}\n      {%- else -%}\n        {{- \" (unable to find a suitable closest zone)\" -}}\n      {%- endif -%}\n    {%- else -%}\n      {{- \" (no zones defined)\" -}}\n    {%- endif -%}\n  {%- else -%}\n    {{- \" (location data unavailable)\" -}}\n  {%- endif -%}\n{%- endmacro -%}\n\n{# Macro to format a timestamp in a friendly way #}\n{%- macro friendly_time(timestamp) -%}\n  {%- set dt = timestamp | as_datetime | as_local -%}\n  {%- set today = now().date() -%}\n  {%- set tomorrow = (now() + timedelta(days=1)).date() -%}\n  {%- set dt_date = dt.date() -%}\n  \n  {%- if dt_date == today -%}\n    {{- \"today at \" ~ (dt | as_timestamp | timestamp_custom('%-I:%M %p')) | lower -}}\n  {%- elif dt_date == tomorrow -%}\n    {{- \"tomorrow at \" ~ (dt | as_timestamp | timestamp_custom('%-I:%M %p')) | lower -}}\n  {%- elif (dt_date - today).days <= 6 and dt_date > today -%}\n    {{- (dt | as_timestamp | timestamp_custom('%A at %-I:%M %p')) | lower -}}\n  {%- else -%}\n    {{- dt | as_timestamp | timestamp_custom('%b %-d at %-I:%M %p') -}}\n  {%- endif -%}\n{%- endmacro -%}\n\n{%- for person in states.person -%}\n  {%- if not loop.first -%}{{ \"\\n\" }}{%- endif -%} {# Ensures each person's status starts on a new line. #}\n  \n  {{- person.name -}}\n  {%- if person.state == 'not_home' -%}\n    {{- \" is not home\" ~ get_not_home_status_details(person) -}}\n  {%- else -%}\n    {# If not 'not_home', the person.state is the friendly name of the zone they are in. #}\n    {{- \" is at \" ~ person.state -}}\n  {%- endif -%}\n  {%- set lat = state_attr(person.entity_id, 'latitude') -%}\n  {%- set lon = state_attr(person.entity_id, 'longitude') -%}\n  {%- if lat is not none and lon is not none -%}\n    {{- \" (\" ~ lat ~ \", \" ~ lon ~ \")\" -}}\n  {%- endif -%}\n{%- endfor -%}\n\n{# Process electricity price forecasts #}\n{%- set forecasts = state_attr(\"sensor.electricity_price_forecast\", \"forecasts\") or [] -%}\n{%- set significant_periods = [] -%}\n{%- set current = namespace(type=none, start=none, end=none, min=none, max=none) -%}\n\n{%- for forecast in forecasts | sort(attribute='start_time') -%}\n  {# Determine if this forecast is significant #}\n  {%- set price_type = none -%}\n  {%- if forecast.per_kwh < 0.15 -%}\n    {%- set price_type = \"very low\" -%} {%- elif forecast.per_kwh < 0.25 -%} {%- set price_type = \"low\" -%}\n  {%- elif forecast.descriptor in [\"high\", \"spike\"] -%}\n    {%- set price_type = \"very high\" -%}\n  {%- endif -%}\n  \n  {%- if price_type -%}\n    {# This is a significant price period #}\n    {%- if not current.type -%}\n      {# Start new period #}\n      {%- set current.type = price_type -%}\n      {%- set current.start = forecast.start_time -%}\n      {%- set current.end = forecast.end_time -%}\n      {%- set current.min = forecast.per_kwh -%}\n      {%- set current.max = forecast.per_kwh -%}\n    {%- elif current.type == price_type and current.end == forecast.start_time -%}\n      {# Extend current period (adjacent and same type) #}\n      {%- set current.end = forecast.end_time -%}\n      {%- set current.min = [current.min, forecast.per_kwh] | min -%}\n      {%- set current.max = [current.max, forecast.per_kwh] | max -%}\n    {%- else -%}\n      {# Save current period and start new one - using safe list concatenation #}\n      {%- set significant_periods = significant_periods + [{\n          \"type\": current.type,\n          \"start\": current.start,\n          \"end\": current.end,\n          \"min\": current.min,\n          \"max\": current.max\n        }] -%}\n      {%- set current.type = price_type -%}\n      {%- set current.start = forecast.start_time -%}\n      {%- set current.end = forecast.end_time -%}\n      {%- set current.min = forecast.per_kwh -%}\n      {%- set current.max = forecast.per_kwh -%}\n    {%- endif -%}\n  {%- elif current.type -%}\n    {# Save current period and reset - using safe list concatenation #}\n    {%- set significant_periods = significant_periods + [{\n        \"type\": current.type,\n        \"start\": current.start,\n        \"end\": current.end,\n        \"min\": current.min,\n        \"max\": current.max\n      }] -%}\n    {%- set current.type = none -%}\n    {%- set current.start = none -%}\n    {%- set current.end = none -%}\n    {%- set current.min = none -%}\n    {%- set current.max = none -%}\n  {%- endif -%}\n{%- endfor -%}\n\n{# Save any remaining period - using safe list concatenation #}\n{%- if current.type -%}\n  {%- set significant_periods = significant_periods + [{\n      \"type\": current.type,\n      \"start\": current.start,\n      \"end\": current.end,\n      \"min\": current.min,\n      \"max\": current.max\n    }] -%}\n{%- endif -%}\n{{ \"\\n\\n\" }}\n## Energy price\nCurrently: {{ states(\"sensor.general_price\") }} ({{ state_attr(\"sensor.general_price\", \"descriptor\") }})\n\n{%- if significant_periods -%}\n  {%- for period in significant_periods %}\nPrice is {{ period.type }} ({{ period.min | round(2) }} to {{ period.max | round(2) }} c/kWh) from {{ friendly_time(period.start) }} to {{ friendly_time(period.end) }}\n  {%- endfor -%}\n{%- else -%}\nNo significant energy price periods are forecast.\n{%- endif -%}\n\n"
    # `prompts` are loaded from prompts.yaml. This key is a placeholder for that structure.
    # prompts:
    #   system_prompt: "You are a helpful assistant. Current time is {current_time}."
    #   # ... other prompts ...

    # Default values, can be overridden by environment variables.
    timezone: "Australia/Sydney"
    max_history_messages: 10
    history_max_age_hours: 2
    # Web-specific history settings for better conversation context
    # web_max_history_messages: 100  # Uncomment to override default of 100
    # web_history_max_age_hours: 720  # Uncomment to override default of 720 (30 days)
    max_iterations: 10 # Maximum number of tool call iterations
    delegation_security_level: "confirm" # Default: "blocked", "confirm", or "unrestricted"
  tools_config:
    # `enable_local_tools` are not explicitly listed here for the default profile.
    # The application currently enables all available local tools.
    enable_local_tools:
      - "add_or_update_note"
      - "get_note"
      - "list_notes"
      - "delete_note"
      - "schedule_future_callback"
      - "schedule_recurring_task"
      - "schedule_reminder"
      - "schedule_action"
      - "schedule_recurring_action"
      - "list_pending_callbacks"
      - "modify_pending_callback"
      - "cancel_pending_callback"
      - "search_documents"
      - "get_full_document_content"
      - "get_attachment_info"
      - "get_message_history"
      - "get_user_documentation_content"
      - "ingest_document_from_url"
      - "execute_script"
      - "send_message_to_user"
      - "attach_to_response"
      - "add_calendar_event"
      - "search_calendar_events"
      - "modify_calendar_event"
      - "delete_calendar_event"
      - "delegate_to_service"
      - "query_recent_events" # Event system tool
      - "render_home_assistant_template" # Home Assistant template rendering
      - "get_camera_snapshot" # Get camera snapshots from Home Assistant
      - "download_state_history" # Download Home Assistant state history as JSON
      - "list_home_assistant_entities" # Search and list Home Assistant entities
      # Read-only automation tools (creation/editing requires automation_creation profile)
      - "list_automations" # List all automations
      - "get_automation" # Get automation details
      - "get_automation_stats" # Get automation execution statistics
      # Image generation tools
      - "generate_image" # Generate images from text using AI
      - "transform_image" # Transform existing images based on instructions
      # Image manipulation tools
      - "highlight_image" # Highlight or annotate areas in images
    enable_mcp_server_ids: # Explicitly define MCP servers for the default profile
      - "time"
      - "brave"
      - "python"
      - "homeassistant"
      - "google-maps"
      # The "browser" mcp server is intentionally excluded here.
    # Tools requiring explicit user confirmation before execution for this default profile.
    # This list is overridden by the TOOLS_REQUIRING_CONFIRMATION environment variable if set.
    confirm_tools:
      - delete_calendar_event
      - modify_calendar_event
      # - tool_that_posts_online
    mcp_initialization_timeout_seconds: 60 # Default 1 minute
  # Default list of slash commands that trigger this profile.
  # Can be overridden by individual service_profiles.
  slash_commands: []
# --- Service Profiles ---
# Defines specific assistant profiles with potentially different configurations.
# Provider Configuration:
# - 'google': Direct Google GenAI SDK integration (requires GEMINI_API_KEY)
# - 'openai': Direct OpenAI SDK integration (requires OPENAI_API_KEY)
# - 'litellm': LiteLLM for models not available via direct integration (default)
service_profiles:
  - id: "default_assistant"
    description: "Main assistant using default settings, without browser tools. Suitable for general tasks, note-taking, calendar management, and information retrieval from stored documents."
    # This profile implicitly uses all settings from 'default_profile_settings'
    # as no specific 'processing_config' or 'tools_config' is defined here,
    # thus inheriting the tools_config that excludes the browser.
  - id: "browser_profile"
    description: "Assistant profile with web browsing capabilities for complex browser interactions like filling forms or navigating JavaScript-heavy sites. For simple web scraping, consider using the ingest_document_from_url tool or direct MCP browser tools."
    processing_config:
      # Using simple format (no retry/fallback for browser tasks)
      provider: "google"
      llm_model: "gemini-3-pro-preview"
      prompts: # MERGES with default_profile_settings.processing_config.prompts
        system_prompt: "You are an assistant with web browsing capabilities interacting with {user_name}. After any tool calls you make, your final text response will be sent directly to {user_name}. Do NOT use the 'send_message_to_user' tool to respond to {user_name} - that tool is only for sending messages to OTHER users. Current time is {current_time}."
      delegation_security_level: "unrestricted" # This profile can be delegated to without forced confirmation
    tools_config: # REPLACES default_profile_settings.tools_config entirely for this profile
      # enable_local_tools: [] # Example: if you want NO local tools for this profile
      enable_mcp_server_ids:
        - "browser" # Only enable the browser MCP server
      confirm_tools: # Define tools requiring confirmation specifically for this profile
        - "browse_url" # Assuming 'browse_url' is a tool from the browser MCP server
    slash_commands:
      - "/browse"
  - id: "research"
    description: "Assistant profile for deep research, utilizing the Perplexity Sonar model. Ideal for comprehensive information gathering and analysis when web browsing or specific tool execution is not required."
    processing_config:
      # Research profile still uses LiteLLM for access to Perplexity models
      provider: "litellm"
      llm_model: "openrouter/perplexity/sonar-deep-research"
      prompts:
        system_prompt: "You are a research assistant interacting with {user_name}. Please focus on providing comprehensive and accurate information. After any tool calls you make, your final text response will be sent directly to {user_name}. Do NOT use the 'send_message_to_user' tool to respond to {user_name} - that tool is only for sending messages to OTHER users."
      # Inherits default timezone, history settings.
      # No specific context providers are added by default for this profile.
      delegation_security_level: "unrestricted"
    tools_config: # REPLACES default_profile_settings.tools_config entirely for this profile
      enable_local_tools: [] # No local tools for this profile
      enable_mcp_server_ids: [] # No MCP tools for this profile
      confirm_tools: [] # No tools to confirm
    slash_commands:
      - "/research"
  - id: "data_visualization"
    description: "Assistant profile optimized for creating data visualizations and charts. Uses Vega/Vega-Lite to generate professional charts from user data."
    processing_config:
      max_iterations: 20
      delegation_security_level: "unrestricted"
      include_system_docs:
        - "data_visualization.md"
        - "vega_lite_reference.md"
    tools_config:
      enable_local_tools:
        - "create_vega_chart"
        - "jq_query"
        - "attach_to_response"
        - "get_attachment_info"
        - "search_documents"
        - "get_full_document_content"
        - "download_state_history"
        - "list_home_assistant_entities"
        - "render_home_assistant_template"
        - "execute_script"
      enable_mcp_server_ids:
        - "python"
        - "homeassistant"
        - "scrape"
    slash_commands:
      - "/visualize"
      - "/chart"
  - id: "event_handler"
    description: "Restricted assistant profile for automated script-event integration. Uses Gemini 3 Pro Preview with read-only and non-destructive tools only."
    processing_config:
      # Using direct Google provider for consistency
      provider: "google"
      llm_model: "gemini-3-pro-preview"
      # Auto-load system documentation into this profile's system prompt
      # include_system_docs:
      #   - "USER_GUIDE.md"
      #   - "scripting.md"
      prompts:
        system_prompt: "You are an automated event handler assistant. You are responding to events from scripts and automations. Provide clear, concise responses focused on the event context.\n\nCurrent time: {current_time}\n\n{aggregated_other_context}"
      max_history_messages: 1 # Minimal history for event processing
      history_max_age_hours: 0.5 # 30 minutes - events are typically immediate
      delegation_security_level: "blocked" # Cannot delegate to other services
    tools_config: # REPLACES default_profile_settings.tools_config entirely for this profile
      enable_local_tools:
        # Core data tools (read/write for notes, read-only for documents)
        - "add_or_update_note"
        - "list_notes"
        - "get_note"
        - "search_documents"
        # Communication (Telegram only to prevent email spam)
        - "send_message_to_user"
        # Calendar read-only
        - "search_calendar_events"
        # Event system query only (no listener creation/modification)
        - "query_recent_events"
      enable_mcp_server_ids:
        # Home Assistant read-only access
        - "homeassistant" # Configured to only allow get_entity_state and get_all_entities
      confirm_tools: [] # No confirmation needed for automated operations
    slash_commands: [] # Not accessible via slash commands
  - id: "automation_creation"
    description: "Specialized profile for creating and validating event-based and schedule-based automations. Includes comprehensive scripting documentation and validation tools."
    processing_config:
      provider: "google"
      llm_model: "gemini-3-pro-preview"
      max_iterations: 25 # Allow more iterations for complex validation workflows
      delegation_security_level: "unrestricted" # Can delegate to other profiles if needed
      include_system_docs:
        - "scripting.md" # Include scripting documentation by default
      prompts:
        system_prompt: |
          You are a specialized automation creation assistant helping {user_name} create robust, well-tested automations.

          Current time: {current_time}

          {aggregated_other_context}

          ## Your Mission

          Your goal is to help users create reliable, validated automations (both event-based and schedule-based) that work correctly on the first try. You achieve this through systematic analysis, validation, and testing before creating the final automation.

          ## Automation Creation Procedure

          When a user asks you to create an automation, follow this systematic approach:

          ### 1. Understand the Request and Examine Existing Patterns

          - **Parse the user's intent**: What do they want to happen? When should it happen? What action should be taken?
          - **Search for similar automations**: Use `list_automations` to find existing automations that do similar things
            - Look for automations that have run successfully before (check `get_automation_stats`)
            - Identify patterns in how similar triggers are implemented
            - Note successful condition script patterns if they exist
          - **Ask clarifying questions** if the request is ambiguous

          ### 2. Identify Trigger Conditions

          Determine what should trigger the automation:

          **For Event-Based Automations:**
          - What event source? (home_assistant, indexing, webhook)
          - What specific entity or data should be watched?
          - What conditions indicate the automation should run?
          - Can conditions be expressed as simple equality checks (match_conditions)?
          - Or do they require complex logic (condition_script with Starlark)?

          **For Schedule-Based Automations:**
          - What time(s) should it run?
          - What recurrence pattern (RRULE format)?
          - Examples: "FREQ=DAILY;BYHOUR=7" for 7am daily, "FREQ=WEEKLY;BYDAY=MO,WE,FR;BYHOUR=9" for Mon/Wed/Fri at 9am

          ### 3. Determine Action Type

          Choose between two action types:

          **Use `action_type="script"` when:**
          - The action is deterministic and doesn't require judgment
          - You can write clear, testable logic for what to do
          - Fast execution is important (scripts run immediately)
          - Examples: logging data, sending notifications with known content, simple data collection

          **Use `action_type="wake_llm"` when:**
          - The action requires reasoning or context-aware judgment
          - The situation is complex and may need different responses
          - You need to analyze multiple factors before deciding what to do
          - Examples: "decide whether to send a reminder based on calendar", "summarize important emails and notify if urgent"

          ### 4. Validate All Assumptions with Tools

          **CRITICAL**: Never guess about entity IDs, event structures, or state values. Always validate:

          **Validate Event Structures:**
          ```
          # Check what events actually look like
          Use query_recent_events(source_id="home_assistant", hours=24, limit=10)
          # Examine the structure of events - what fields exist? What are the actual values?
          ```

          **Validate Entity IDs and States:**
          ```
          # For Home Assistant entities
          Use MCP homeassistant tools to:
          - Get current state: get_entity_state(entity_id="sensor.temperature")
          - List available entities: get_all_entities() then filter/search

          # Check historical state data
          Use download_state_history(entity_ids=["sensor.temperature"], hours=24)
          # Verify that assumed states/attributes actually exist in this format
          ```

          **Test Event Matching:**
          ```
          # Before creating an event automation, test if your conditions would actually match
          Use test_event_listener(
              source="home_assistant",
              match_conditions={"entity_id": "sensor.motion", "new_state.state": "on"},
              hours=24,
              limit=5
          )
          # This shows you if your conditions would have matched recent events
          ```

          ### 5. Generate and Test Candidate Scripts

          **For script-based actions:**

          - Write a candidate action script
          - Test it in isolation first using `execute_script` with test data
          - Verify it produces the expected results
          - Check for edge cases (missing data, null values, etc.)
          - For event scripts, simulate the event structure you validated in step 4

          **For condition scripts (complex event matching):**

          - Write a candidate condition script
          - Test it against actual event data from `query_recent_events`
          - Verify it returns boolean values correctly
          - Check it handles missing fields gracefully (use `.get()` with defaults)
          - Remember: Starlark has no float(), only int(). For decimal temperatures, truncate: `int(event.get('new_state', {}).get('state', '0').split('.')[0])`

          **Example Testing Pattern:**
          ```python
          # Test a temperature condition script
          test_script = '''
          temp = int(event.get("new_state", {}).get("state", "0").split('.')[0])
          old_temp = int(event.get("old_state", {}).get("state", "0").split('.')[0]) if event.get("old_state") else 0
          return temp > 25 and old_temp <= 25  # Crossing threshold
          '''

          # Execute with sample event data to verify it works
          result = execute_script(
              script_code=test_script,
              global_vars={"event": sample_event_from_query_recent_events}
          )
          ```

          ### 6. Test Actions Safely

          **Before creating the automation:**

          - For notification actions: Test the message format makes sense
          - For wake_llm actions: Verify the context will be clear to the LLM when it wakes
          - For data modification: Consider if a dry-run is possible
          - For scripts with side effects: Test with minimal impact first

          **Dry-run strategies:**
          - Add a `dry_run=True` flag to your script and only log what would happen
          - Test with a copy of data rather than production data
          - Send test notifications to yourself first

          ### 7. Validate wake_llm Context

          **For wake_llm automations:**

          - Put yourself in the LLM's position when it wakes up
          - Will the context be clear? Will it have enough information to act?
          - Is the context message specific and actionable?

          **Good wake_llm context examples:**
          - "Motion detected in garage at 2:30 AM - unusual activity"
          - "Temperature in living room reached 28°C, above comfortable range"
          - "New email from project manager with 'urgent' in subject"

          **Poor wake_llm context examples:**
          - "Event occurred" (too vague)
          - "State changed" (no actionable information)
          - "Check this" (LLM won't know what to check)

          ### 8. Create the Automation

          Once validated and tested:

          ```python
          # Create the automation with all validated parameters
          result = create_automation(
              name="Descriptive name of what this does",
              automation_type="event",  # or "schedule"
              trigger_config={
                  # For event type:
                  "event_source": "home_assistant",
                  "event_filter": {...},  # Validated filters
                  # Optional: "condition_script": "..." if complex matching needed

                  # For schedule type:
                  # "recurrence_rule": "FREQ=DAILY;BYHOUR=7"
              },
              action_type="script",  # or "wake_llm"
              action_config={
                  # For script type:
                  "script_code": "...",  # Tested script

                  # For wake_llm type:
                  "context": "Clear message explaining what happened and why LLM should care"
              },
              description="Optional longer description of purpose and behavior"
          )
          ```

          ### 9. Provide Results and Next Steps

          After creating the automation:

          - Show the automation ID from the result
          - Provide a direct link to view it in the UI: `{server_url}/automations/event/{automation_id}` or `{server_url}/automations/schedule/{automation_id}`
          - Explain what will trigger it and what it will do
          - Suggest how to verify it's working (check stats, watch for next trigger, etc.)
          - Offer to make adjustments if needed

          ## Important Guidelines

          **Always validate before creating:**
          - Use tools to verify entity IDs exist
          - Check event structures match your assumptions
          - Test scripts before embedding them in automations
          - Validate that historical data shows the patterns you expect

          **Prefer scripts over wake_llm when possible:**
          - Scripts are faster (no API calls)
          - Scripts are more deterministic
          - Scripts are cheaper (no LLM costs)
          - Only use wake_llm when genuine reasoning is needed

          **Write defensive scripts:**
          - Use `.get()` with defaults for optional fields
          - Check for None/empty values before processing
          - Remember Starlark limitations: no try/except, no while loops, no float()
          - Handle missing event fields gracefully

          **Make automations debuggable:**
          - Use descriptive names that explain what they do
          - Add meaningful descriptions
          - For scripts, include comments explaining logic
          - For wake_llm, provide context that will help future debugging

          **Consider rate limiting:**
          - Event automations have daily execution limits (default 5/day)
          - Design conditions to avoid excessive triggering
          - Use condition scripts to filter out noise

          ## Common Patterns

          **Zone entry detection:**
          ```starlark
          # Detect when someone enters home zone
          old_state = event.get('old_state', {}).get('state', '')
          new_state = event.get('new_state', {}).get('state', '')
          return old_state != 'home' and new_state == 'home'
          ```

          **Threshold crossing:**
          ```starlark
          # Alert when temperature crosses above 25°C
          temp = int(event.get("new_state", {}).get("state", "0").split('.')[0])
          old_temp = int(event.get("old_state", {}).get("state", "0").split('.')[0]) if event.get("old_state") else 0
          return temp > 25 and old_temp <= 25
          ```

          **Pattern matching:**
          ```starlark
          # Match any motion sensor
          entity_id = event.get('entity_id', '')
          new_state = event.get('new_state', {}).get('state', '')
          return entity_id.startswith('sensor.motion_') and new_state == 'on'
          ```

          ## Remember

          You have access to comprehensive scripting documentation (already loaded). Reference it when writing scripts. The scripting guide covers:
          - Starlark language features and limitations
          - Available tool APIs and how to call them
          - Time/date handling functions
          - Attachment creation and manipulation
          - Common patterns and examples

          Your success is measured by creating automations that work reliably without manual intervention. Take the time to validate, test, and verify before creating.
    tools_config:
      enable_local_tools:
        # Automation management tools
        - "create_automation"
        - "list_automations"
        - "get_automation"
        - "update_automation"
        - "enable_automation"
        - "disable_automation"
        - "delete_automation"
        - "get_automation_stats"
        # Event testing and validation tools
        - "query_recent_events"
        - "test_event_listener"
        # Script execution for testing
        - "execute_script"
        # Calendar and notes for context
        - "search_calendar_events"
        - "get_calendar_events"
        - "list_notes"
        - "get_note"
        - "search_notes"
        # Communication tools
        - "send_message_to_user"
        # Document access for understanding context
        - "search_documents"
        - "get_full_document_content"
        - "get_user_documentation_content"
        # Home Assistant state validation
        - "download_state_history"
        - "render_home_assistant_template"
        # Callback and action scheduling
        - "schedule_action"
        - "schedule_recurring_action"
        - "list_pending_callbacks"
      enable_mcp_server_ids:
        - "homeassistant" # For validating entity IDs and states
      confirm_tools: [] # No confirmation needed for automation creation workflows
    slash_commands:
      - "/automate"
# Other global settings like llm_parameters, indexing_pipeline_config remain at top level.
# Attachment handling configuration
attachment_config:
  # Maximum file size for general attachments (in bytes)
  # Default: 100MB to handle large documents/images
  max_file_size: 104857600 # 100 * 1024 * 1024

  # Maximum file size for multimodal LLM processing (in bytes)
  # This is typically lower due to LLM provider limits
  # Default: 20MB (most LLM providers support up to 20MB images)
  max_multimodal_size: 20971520 # 20 * 1024 * 1024

  # Storage path for chat attachments
  # Can be overridden by chat_attachment_storage_path for backward compatibility
  storage_path: "/tmp/chat_attachments"

  # Allowed MIME types for attachments
  allowed_mime_types:
    - "image/jpeg"
    - "image/png"
    - "image/gif"
    - "image/webp"
    - "image/bmp"
    - "image/tiff"
    - "application/pdf"
    - "text/plain"
    - "application/json"
    - "text/csv"
    - "application/vnd.openxmlformats-officedocument.wordprocessingml.document"
    - "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
    - "application/vnd.openxmlformats-officedocument.presentationml.presentation"

# Secrets (telegram_token, api_keys, database_url) are primarily from env.
# Model, embedding_model, server_url, storage_paths are also top-level or env.

