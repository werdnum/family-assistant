import logging
import uuid
from typing import Annotated

from fastapi import APIRouter, Depends, HTTPException, Request, status

from family_assistant.processing import ProcessingService
from family_assistant.storage.context import DatabaseContext
from family_assistant.web.dependencies import get_db, get_processing_service
from family_assistant.web.models import ChatMessageResponse, ChatPromptRequest

logger = logging.getLogger(__name__)
chat_api_router = APIRouter()


@chat_api_router.post("/v1/chat/send_message")  # Path relative to the prefix in api.py
async def api_chat_send_message(
    payload: ChatPromptRequest,
    request: Request,  # To access app.state for config and service registry
    default_processing_service: Annotated[
        ProcessingService, Depends(get_processing_service)
    ],  # Renamed for clarity
    db_context: Annotated[DatabaseContext, Depends(get_db)],
) -> ChatMessageResponse:
    """
    Receives a user prompt via API, processes it using the specified or default
    ProcessingService, and returns the assistant's reply.
    """
    conversation_id = payload.conversation_id or f"api_conv_{uuid.uuid4()}"
    # turn_id is generated internally by handle_chat_interaction.
    # We will use a placeholder for the response model if needed, or remove it from response.

    # Determine which processing service to use
    selected_processing_service = default_processing_service
    profile_id_requested = payload.profile_id

    if profile_id_requested:
        logger.info(
            f"API chat request for profile_id: '{profile_id_requested}'. Conversation ID: {conversation_id}, Prompt: '{payload.prompt[:100]}...'"
        )
        processing_services_registry = getattr(
            request.app.state, "processing_services", {}
        )
        if profile_id_requested in processing_services_registry:
            selected_processing_service = processing_services_registry[
                profile_id_requested
            ]
            logger.info(
                f"Using ProcessingService for profile_id: '{profile_id_requested}'."
            )
        else:
            logger.warning(
                f"Profile_id '{profile_id_requested}' not found in registry. Falling back to default profile: '{default_processing_service.service_config.id}'."
            )
    else:
        logger.info(
            f"API chat request (no profile_id specified). Using default profile: '{default_processing_service.service_config.id}'. Conversation ID: {conversation_id}, Prompt: '{payload.prompt[:100]}...'"
        )

    # Prepare trigger_content_parts for the new service method
    trigger_content_parts = [{"type": "text", "text": payload.prompt}]

    # Call the new centralized interaction handler
    # For API, user_name can be generic or derived from auth if implemented
    user_name_for_api = (
        "API User"  # payload.user_name is not available on ChatPromptRequest
    )

    # The `turn_id` will be generated by `handle_chat_interaction`
    # We can retrieve it from the response if needed by the client,
    # but the ChatMessageResponse model currently expects it.
    # Let's assume for now the client might want the turn_id.
    # The `handle_chat_interaction` doesn't return turn_id directly,
    # but it's logged and associated with messages.
    # For the API response, we might need to reconsider if turn_id is essential.
    # The current ChatMessageResponse model includes it.
    # Let's generate it here for the response, though the one used internally will be from handle_chat_interaction.
    # This is a slight divergence; ideally, the one from handle_chat_interaction would be returned.
    # For now, to match the existing response model:
    response_turn_id = (
        f"api_turn_{uuid.uuid4()}"  # This is for the *response model only*
    )

    (
        final_reply_content,
        _final_assistant_message_internal_id,  # Not used by API response
        _final_reasoning_info,  # Not used by API response
        error_traceback,
    ) = await selected_processing_service.handle_chat_interaction(
        db_context=db_context,
        interface_type="api",
        conversation_id=conversation_id,
        trigger_content_parts=trigger_content_parts,
        trigger_interface_message_id=None,  # API prompts don't have a prior interface ID
        user_name=user_name_for_api,
        replied_to_interface_id=None,  # payload.replied_to_message_id is not available on ChatPromptRequest
        chat_interface=None,  # API doesn't use interactive chat elements for confirmation (yet)
        new_task_event=None,  # No task event for synchronous API response
        request_confirmation_callback=None,  # No confirmation callback for API (yet)
    )

    if error_traceback:
        logger.error(
            f"Error processing API chat request for Conversation ID {conversation_id}: {error_traceback}"
        )
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error processing request: {error_traceback if request.app.state.debug_mode else 'An internal error occurred.'}",
        )

    if final_reply_content is None:
        logger.error(
            f"No final assistant reply content found for API chat. Conversation ID: {conversation_id}"
        )
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Assistant did not provide a textual reply.",
        )

    return ChatMessageResponse(
        reply=final_reply_content,
        conversation_id=conversation_id,  # Return the used/generated conversation_id
        turn_id=response_turn_id,  # Return the turn_id generated for the response model
    )
