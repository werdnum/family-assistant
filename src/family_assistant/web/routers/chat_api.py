import logging
import uuid
from typing import Annotated

from fastapi import APIRouter, Depends, HTTPException, Request, status

from family_assistant.processing import ProcessingService
from family_assistant.storage.context import DatabaseContext
from family_assistant.web.dependencies import get_db, get_processing_service
from family_assistant.web.models import ChatMessageResponse, ChatPromptRequest

logger = logging.getLogger(__name__)
chat_api_router = APIRouter()


@chat_api_router.post("/v1/chat/send_message")  # Path relative to the prefix in api.py
async def api_chat_send_message(
    payload: ChatPromptRequest,
    request: Request,  # To access app.state for config if needed by ProcessingService context
    processing_service: Annotated[ProcessingService, Depends(get_processing_service)],
    db_context: Annotated[DatabaseContext, Depends(get_db)],
) -> ChatMessageResponse:
    """
    Receives a user prompt via API, processes it using the ProcessingService,
    and returns the assistant's reply.
    """
    conversation_id = payload.conversation_id or f"api_conv_{uuid.uuid4()}"
    turn_id = f"api_turn_{uuid.uuid4()}"

    logger.info(
        f"API chat request received. Conversation ID: {conversation_id}, Turn ID: {turn_id}, Prompt: '{payload.prompt[:100]}...'"
    )

    # Prepare messages for ProcessingService
    user_message = {"role": "user", "content": payload.prompt}
    # For API, each call is typically independent unless conversation_id is managed by client
    # If conversation_id is provided, history could be fetched, but for now, simple single message processing.
    messages_to_process = [user_message]  # This is for the LLM, not for saving directly

    # The turn_id is now generated by handle_chat_interaction.
    # We will get it back in the response if needed.

    logger.info(
        f"API chat request received. Conversation ID: {conversation_id}, Prompt: '{payload.prompt[:100]}...'"
    )

    # Prepare trigger_content_parts for the new service method
    trigger_content_parts = [{"type": "text", "text": payload.prompt}]

    # Call the new centralized interaction handler
    # For API, user_name can be generic or derived from auth if implemented
    user_name_for_api = payload.user_name or "API User"
    
    # The `turn_id` will be generated by `handle_chat_interaction`
    # We can retrieve it from the response if needed by the client,
    # but the ChatMessageResponse model currently expects it.
    # Let's assume for now the client might want the turn_id.
    # The `handle_chat_interaction` doesn't return turn_id directly,
    # but it's logged and associated with messages.
    # For the API response, we might need to reconsider if turn_id is essential.
    # The current ChatMessageResponse model includes it.
    # Let's generate it here for the response, though the one used internally will be from handle_chat_interaction.
    # This is a slight divergence; ideally, the one from handle_chat_interaction would be returned.
    # For now, to match the existing response model:
    response_turn_id = f"api_turn_{uuid.uuid4()}"  # This is for the *response model only*

    (
        final_reply_content,
        _final_assistant_message_internal_id,  # Not used by API response
        _final_reasoning_info,  # Not used by API response
        error_traceback,
    ) = await processing_service.handle_chat_interaction(
        db_context=db_context,
        interface_type="api",
        conversation_id=conversation_id,
        trigger_content_parts=trigger_content_parts,
        trigger_interface_message_id=None,  # API prompts don't have a prior interface ID
        user_name=user_name_for_api,
        replied_to_interface_id=payload.replied_to_message_id,  # Pass if provided
        chat_interface=None,  # API doesn't use interactive chat elements for confirmation (yet)
        new_task_event=None,  # No task event for synchronous API response
        request_confirmation_callback=None,  # No confirmation callback for API (yet)
    )

    if error_traceback:
        logger.error(
            f"Error processing API chat request for Conversation ID {conversation_id}: {error_traceback}"
        )
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Error processing request: {error_traceback if request.app.state.debug_mode else 'An internal error occurred.'}",
        )

    if final_reply_content is None:
        logger.error(
            f"No final assistant reply content found for API chat. Conversation ID: {conversation_id}"
        )
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail="Assistant did not provide a textual reply.",
        )

    return ChatMessageResponse(
        reply=final_reply_content,
        conversation_id=conversation_id,  # Return the used/generated conversation_id
        turn_id=response_turn_id,  # Return the turn_id generated for the response model
    )
