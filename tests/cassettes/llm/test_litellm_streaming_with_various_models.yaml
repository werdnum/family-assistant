interactions:
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.2
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.2
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.12.3
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: 'data: {"id":"chatcmpl-By7q00JDxRIW4zst9oOi6w8Oc7397","object":"chat.completion.chunk","created":1753669508,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_38343a2f8f","choices":[{"index":0,"delta":{"role":"assistant","content":"","refusal":null},"logprobs":null,"finish_reason":null}],"usage":null}


          data: {"id":"chatcmpl-By7q00JDxRIW4zst9oOi6w8Oc7397","object":"chat.completion.chunk","created":1753669508,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_38343a2f8f","choices":[{"index":0,"delta":{"content":"Lite"},"logprobs":null,"finish_reason":null}],"usage":null}


          data: {"id":"chatcmpl-By7q00JDxRIW4zst9oOi6w8Oc7397","object":"chat.completion.chunk","created":1753669508,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_38343a2f8f","choices":[{"index":0,"delta":{"content":"LL"},"logprobs":null,"finish_reason":null}],"usage":null}


          data: {"id":"chatcmpl-By7q00JDxRIW4zst9oOi6w8Oc7397","object":"chat.completion.chunk","created":1753669508,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_38343a2f8f","choices":[{"index":0,"delta":{"content":"M"},"logprobs":null,"finish_reason":null}],"usage":null}


          data: {"id":"chatcmpl-By7q00JDxRIW4zst9oOi6w8Oc7397","object":"chat.completion.chunk","created":1753669508,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_38343a2f8f","choices":[{"index":0,"delta":{"content":" streaming"},"logprobs":null,"finish_reason":null}],"usage":null}


          data: {"id":"chatcmpl-By7q00JDxRIW4zst9oOi6w8Oc7397","object":"chat.completion.chunk","created":1753669508,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_38343a2f8f","choices":[{"index":0,"delta":{"content":" works"},"logprobs":null,"finish_reason":null}],"usage":null}


          data: {"id":"chatcmpl-By7q00JDxRIW4zst9oOi6w8Oc7397","object":"chat.completion.chunk","created":1753669508,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_38343a2f8f","choices":[{"index":0,"delta":{"content":"!"},"logprobs":null,"finish_reason":null}],"usage":null}


          data: {"id":"chatcmpl-By7q00JDxRIW4zst9oOi6w8Oc7397","object":"chat.completion.chunk","created":1753669508,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_38343a2f8f","choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}],"usage":null}


          data: {"id":"chatcmpl-By7q00JDxRIW4zst9oOi6w8Oc7397","object":"chat.completion.chunk","created":1753669508,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_38343a2f8f","choices":[],"usage":{"prompt_tokens":18,"completion_tokens":6,"total_tokens":24,"prompt_tokens_details":{"cached_tokens":0,"audio_tokens":0},"completion_tokens_details":{"reasoning_tokens":0,"audio_tokens":0,"accepted_prediction_tokens":0,"rejected_prediction_tokens":0}}}


          data: [DONE]


'
      headers:
        CF-RAY:
          - 9660ec975d70e7c4-SYD
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Mon, 28 Jul 2025 02:25:08 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=qcMiXV578EMW88FtIRnqps3s0LV9ov3bzR7QAwg5uNw-1753669508-1.0.1.1-Mknvy7O46d.pmKA0QiorMoWZR9TLYjqqcsg5xZTYSQeTdtKm8QtW50MS970DO7fCGNZRc.yVkgZ4FvdfUy4LpnkkHNQF5jWoz9H_15PSNiE; path=/; expires=Mon, 28-Jul-25 02:55:08 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=aebsWhQLw79Ura43MFwHnrGRbVL3PBYpurcNbnwmxs4-1753669508454-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        access-control-expose-headers:
          - X-Request-ID
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '90'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        strict-transport-security:
          - max-age=31536000; includeSubDomains; preload
        x-envoy-upstream-service-time:
          - '94'
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_f7f0fcc1a25e6162f477e1c3292c9e6b
      status:
        code: 200
        message: OK
<<<<<<< HEAD
=======
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: 'data: {"id":"chatcmpl-CdwqH5CCMe2qnemBzdCX4g5Rt6aU6","object":"chat.completion.chunk","created":1763637017,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"role":"assistant","content":"","refusal":null},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"Vl9pNjp4"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CdwqH5CCMe2qnemBzdCX4g5Rt6aU6","object":"chat.completion.chunk","created":1763637017,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"Lite"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"0WnRib"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CdwqH5CCMe2qnemBzdCX4g5Rt6aU6","object":"chat.completion.chunk","created":1763637017,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"LL"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"DnMPk6zS"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CdwqH5CCMe2qnemBzdCX4g5Rt6aU6","object":"chat.completion.chunk","created":1763637017,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"M"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"nKh8ERYIJ"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CdwqH5CCMe2qnemBzdCX4g5Rt6aU6","object":"chat.completion.chunk","created":1763637017,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" streaming"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":""} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CdwqH5CCMe2qnemBzdCX4g5Rt6aU6","object":"chat.completion.chunk","created":1763637017,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" works"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"XTQ0"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CdwqH5CCMe2qnemBzdCX4g5Rt6aU6","object":"chat.completion.chunk","created":1763637017,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"!"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"uaTR46Pi1"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CdwqH5CCMe2qnemBzdCX4g5Rt6aU6","object":"chat.completion.chunk","created":1763637017,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}],"usage":null,"obfuscation":"Ozn7"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CdwqH5CCMe2qnemBzdCX4g5Rt6aU6","object":"chat.completion.chunk","created":1763637017,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[],"usage":{"prompt_tokens":18,"completion_tokens":6,"total_tokens":24,"prompt_tokens_details":{"cached_tokens":0,"audio_tokens":0},"completion_tokens_details":{"reasoning_tokens":0,"audio_tokens":0,"accepted_prediction_tokens":0,"rejected_prediction_tokens":0}},"obfuscation":"8Snm5NMKb2"} #magic___^_^___line #magic___^_^___line data: [DONE] #magic___^_^___line #magic___^_^___line '
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a177ffd0e1e9bce-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Thu, 20 Nov 2025 11:10:17 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=Jr0wVA0MavpxFzgwp16POGk0KbP1Yhd_bVbnHNxvnBs-1763637017-1.0.1.1-iwnAchmUN7ErI_WGVLaJGTZS1T66u5GrcGo3YKwzyyFCq0cza5tclpGqNMAYhPBIXsMxUv2Rqa_U63Eha7CWRy_U3v_PNOk82J5jaWeUk0E; path=/; expires=Thu, 20-Nov-25 11:40:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=6cD_b97By4161zWyVjLvS6SQN2WWjf5x4uzKtkPswMg-1763637017540-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '259'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '273'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_6f8323063e0747c48e834725d6a82d0e
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a177ffd0e1e9bce-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Thu, 20 Nov 2025 11:10:17 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=Jr0wVA0MavpxFzgwp16POGk0KbP1Yhd_bVbnHNxvnBs-1763637017-1.0.1.1-iwnAchmUN7ErI_WGVLaJGTZS1T66u5GrcGo3YKwzyyFCq0cza5tclpGqNMAYhPBIXsMxUv2Rqa_U63Eha7CWRy_U3v_PNOk82J5jaWeUk0E; path=/; expires=Thu, 20-Nov-25 11:40:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=6cD_b97By4161zWyVjLvS6SQN2WWjf5x4uzKtkPswMg-1763637017540-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '259'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '273'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_6f8323063e0747c48e834725d6a82d0e
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: 'data: {"id":"chatcmpl-CeFprNWTSVf8J1aqsWADUmtWkM67s","object":"chat.completion.chunk","created":1763710027,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"role":"assistant","content":"","refusal":null},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"vst8V7SX"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeFprNWTSVf8J1aqsWADUmtWkM67s","object":"chat.completion.chunk","created":1763710027,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"Lite"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"KzTC9o"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeFprNWTSVf8J1aqsWADUmtWkM67s","object":"chat.completion.chunk","created":1763710027,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"LL"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"jitKaVO4"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeFprNWTSVf8J1aqsWADUmtWkM67s","object":"chat.completion.chunk","created":1763710027,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"M"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"BvlGjsm6h"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeFprNWTSVf8J1aqsWADUmtWkM67s","object":"chat.completion.chunk","created":1763710027,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" streaming"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":""} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeFprNWTSVf8J1aqsWADUmtWkM67s","object":"chat.completion.chunk","created":1763710027,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" works"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"Yke9"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeFprNWTSVf8J1aqsWADUmtWkM67s","object":"chat.completion.chunk","created":1763710027,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"!"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"MWY64isOT"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeFprNWTSVf8J1aqsWADUmtWkM67s","object":"chat.completion.chunk","created":1763710027,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}],"usage":null,"obfuscation":"k1IB"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeFprNWTSVf8J1aqsWADUmtWkM67s","object":"chat.completion.chunk","created":1763710027,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[],"usage":{"prompt_tokens":18,"completion_tokens":6,"total_tokens":24,"prompt_tokens_details":{"cached_tokens":0,"audio_tokens":0},"completion_tokens_details":{"reasoning_tokens":0,"audio_tokens":0,"accepted_prediction_tokens":0,"rejected_prediction_tokens":0}},"obfuscation":"wtQ64y1VTN"} #magic___^_^___line #magic___^_^___line data: [DONE] #magic___^_^___line #magic___^_^___line '
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1e7674ab9e9748-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 07:27:07 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=L0diBKledYCOY1nbtuCM7E2S8wTJalA8VduxXQyjOlc-1763710027-1.0.1.1-yH7mlZcGgAS1AX5eWLMLadZXjW.KVcVBnY0a8hfayPZBCk06THskEjON0xw8CfTJSAc2dGQVZHG.O_l1OYzRheUXjP97oF9o5oypVPyq4lg; path=/; expires=Fri, 21-Nov-25 07:57:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=lf7hIVzKnGFUB.IaegoebH6kSMguaYtvOf78qOiY2Vo-1763710027450-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '275'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '288'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_0f9db872c0764875adcd8945a7ad49d9
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1e7674ab9e9748-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 07:27:07 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=L0diBKledYCOY1nbtuCM7E2S8wTJalA8VduxXQyjOlc-1763710027-1.0.1.1-yH7mlZcGgAS1AX5eWLMLadZXjW.KVcVBnY0a8hfayPZBCk06THskEjON0xw8CfTJSAc2dGQVZHG.O_l1OYzRheUXjP97oF9o5oypVPyq4lg; path=/; expires=Fri, 21-Nov-25 07:57:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=lf7hIVzKnGFUB.IaegoebH6kSMguaYtvOf78qOiY2Vo-1763710027450-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '275'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '288'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_0f9db872c0764875adcd8945a7ad49d9
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: 'data: {"id":"chatcmpl-CeIbvTRIe4fmx6nxwGjNe9ONC4seD","object":"chat.completion.chunk","created":1763720695,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"role":"assistant","content":"","refusal":null},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"awRmMKGP"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIbvTRIe4fmx6nxwGjNe9ONC4seD","object":"chat.completion.chunk","created":1763720695,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"Lite"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"u31NpM"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIbvTRIe4fmx6nxwGjNe9ONC4seD","object":"chat.completion.chunk","created":1763720695,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"LL"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"ffnT2EY3"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIbvTRIe4fmx6nxwGjNe9ONC4seD","object":"chat.completion.chunk","created":1763720695,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"M"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"BCCiYrjuh"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIbvTRIe4fmx6nxwGjNe9ONC4seD","object":"chat.completion.chunk","created":1763720695,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" streaming"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":""} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIbvTRIe4fmx6nxwGjNe9ONC4seD","object":"chat.completion.chunk","created":1763720695,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" works"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"wXAi"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIbvTRIe4fmx6nxwGjNe9ONC4seD","object":"chat.completion.chunk","created":1763720695,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"!"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"j8KCAWDeM"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIbvTRIe4fmx6nxwGjNe9ONC4seD","object":"chat.completion.chunk","created":1763720695,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}],"usage":null,"obfuscation":"4N3E"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIbvTRIe4fmx6nxwGjNe9ONC4seD","object":"chat.completion.chunk","created":1763720695,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[],"usage":{"prompt_tokens":18,"completion_tokens":6,"total_tokens":24,"prompt_tokens_details":{"cached_tokens":0,"audio_tokens":0},"completion_tokens_details":{"reasoning_tokens":0,"audio_tokens":0,"accepted_prediction_tokens":0,"rejected_prediction_tokens":0}},"obfuscation":"cRvwebNyI9"} #magic___^_^___line #magic___^_^___line data: [DONE] #magic___^_^___line #magic___^_^___line '
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1f7ae7c8178eb5-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:24:55 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=DmYvZ9DV4L4XwTLLwplmgv1iVv5Frg6yITRyXuFHGPA-1763720695-1.0.1.1-Mnq1RLuwVz_Bwuo8G2B83cYVXrQqoV137rs346YM2ouwnYrtqk7ErTg1BvDMMsQsdpoIerZ7ovPRfpknSHBp5BI74JX3alvscxWm0mPwTTs; path=/; expires=Fri, 21-Nov-25 10:54:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=l5Z81ynWWkL5._GIa2yvaT_T3vtXlH_m7lcDflfYKyo-1763720695435-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '271'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '287'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_cea8a6e881224cf9a39603272278aea2
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1f7ae7c8178eb5-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:24:55 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=DmYvZ9DV4L4XwTLLwplmgv1iVv5Frg6yITRyXuFHGPA-1763720695-1.0.1.1-Mnq1RLuwVz_Bwuo8G2B83cYVXrQqoV137rs346YM2ouwnYrtqk7ErTg1BvDMMsQsdpoIerZ7ovPRfpknSHBp5BI74JX3alvscxWm0mPwTTs; path=/; expires=Fri, 21-Nov-25 10:54:55 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=l5Z81ynWWkL5._GIa2yvaT_T3vtXlH_m7lcDflfYKyo-1763720695435-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '271'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '287'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_cea8a6e881224cf9a39603272278aea2
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: 'data: {"id":"chatcmpl-CeIelCz2jZ7CVtCsMdX4NGTWlzne4","object":"chat.completion.chunk","created":1763720871,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"role":"assistant","content":"","refusal":null},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"ExF77mGD"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIelCz2jZ7CVtCsMdX4NGTWlzne4","object":"chat.completion.chunk","created":1763720871,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"Lite"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"NiMrDy"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIelCz2jZ7CVtCsMdX4NGTWlzne4","object":"chat.completion.chunk","created":1763720871,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"LL"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"inn5Pi03"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIelCz2jZ7CVtCsMdX4NGTWlzne4","object":"chat.completion.chunk","created":1763720871,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"M"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"m7ammShsP"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIelCz2jZ7CVtCsMdX4NGTWlzne4","object":"chat.completion.chunk","created":1763720871,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" streaming"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":""} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIelCz2jZ7CVtCsMdX4NGTWlzne4","object":"chat.completion.chunk","created":1763720871,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" works"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"fIOm"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIelCz2jZ7CVtCsMdX4NGTWlzne4","object":"chat.completion.chunk","created":1763720871,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"!"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"lYrPduviG"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIelCz2jZ7CVtCsMdX4NGTWlzne4","object":"chat.completion.chunk","created":1763720871,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}],"usage":null,"obfuscation":"ILeP"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIelCz2jZ7CVtCsMdX4NGTWlzne4","object":"chat.completion.chunk","created":1763720871,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[],"usage":{"prompt_tokens":18,"completion_tokens":6,"total_tokens":24,"prompt_tokens_details":{"cached_tokens":0,"audio_tokens":0},"completion_tokens_details":{"reasoning_tokens":0,"audio_tokens":0,"accepted_prediction_tokens":0,"rejected_prediction_tokens":0}},"obfuscation":"C1irGp9xXd"} #magic___^_^___line #magic___^_^___line data: [DONE] #magic___^_^___line #magic___^_^___line '
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1f7f344faa9874-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:27:52 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=YWmsZY_56qYdnSa_L9RG1DGTvCsPPAc51XOzFhy1XYw-1763720872-1.0.1.1-47B0tmLIc9vg9SqTfL3PuQL_ay6_3yJU4UUkgOdRzCSL3u_Omnrnv.rz5DFJZja7epnu6pYQ0nGQ1yrnlR_yzCfbAg6LyEk4_.kz2LNUlJ4; path=/; expires=Fri, 21-Nov-25 10:57:52 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=abuFSH4f3wbm6HfsLAxBj6dkN4RautvWa1QyAntTRXI-1763720872162-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '263'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '468'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_e2d209115c694d51a1bfd4afce9947f7
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1f7f344faa9874-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:27:52 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=YWmsZY_56qYdnSa_L9RG1DGTvCsPPAc51XOzFhy1XYw-1763720872-1.0.1.1-47B0tmLIc9vg9SqTfL3PuQL_ay6_3yJU4UUkgOdRzCSL3u_Omnrnv.rz5DFJZja7epnu6pYQ0nGQ1yrnlR_yzCfbAg6LyEk4_.kz2LNUlJ4; path=/; expires=Fri, 21-Nov-25 10:57:52 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=abuFSH4f3wbm6HfsLAxBj6dkN4RautvWa1QyAntTRXI-1763720872162-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '263'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '468'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_e2d209115c694d51a1bfd4afce9947f7
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: 'data: {"id":"chatcmpl-CeIvlEWvO0kRnCP6Go5HhtUig0JFx","object":"chat.completion.chunk","created":1763721925,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"role":"assistant","content":"","refusal":null},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"dZrAl8m4"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIvlEWvO0kRnCP6Go5HhtUig0JFx","object":"chat.completion.chunk","created":1763721925,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"Lite"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"ZeozTu"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIvlEWvO0kRnCP6Go5HhtUig0JFx","object":"chat.completion.chunk","created":1763721925,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"LL"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"6HOUkg9s"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIvlEWvO0kRnCP6Go5HhtUig0JFx","object":"chat.completion.chunk","created":1763721925,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"M"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"CTsCzmkgl"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIvlEWvO0kRnCP6Go5HhtUig0JFx","object":"chat.completion.chunk","created":1763721925,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" streaming"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":""} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIvlEWvO0kRnCP6Go5HhtUig0JFx","object":"chat.completion.chunk","created":1763721925,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" works"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"nQZr"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIvlEWvO0kRnCP6Go5HhtUig0JFx","object":"chat.completion.chunk","created":1763721925,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"!"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"ujcKUXKqr"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIvlEWvO0kRnCP6Go5HhtUig0JFx","object":"chat.completion.chunk","created":1763721925,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}],"usage":null,"obfuscation":"LCMy"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIvlEWvO0kRnCP6Go5HhtUig0JFx","object":"chat.completion.chunk","created":1763721925,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[],"usage":{"prompt_tokens":18,"completion_tokens":6,"total_tokens":24,"prompt_tokens_details":{"cached_tokens":0,"audio_tokens":0},"completion_tokens_details":{"reasoning_tokens":0,"audio_tokens":0,"accepted_prediction_tokens":0,"rejected_prediction_tokens":0}},"obfuscation":"9debk8bBik"} #magic___^_^___line #magic___^_^___line data: [DONE] #magic___^_^___line #magic___^_^___line '
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1f98f20dc5d2bf-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:45:25 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=_VG8TZ8A7B5ZJgfRcE4YsCLWQj3koQ15K2UpjIA8jIU-1763721925-1.0.1.1-EmM6jA8RGyK4ijrUCclE0QgSaM78wQJZQ4uAvj6Nmj4slQVL1DSSVP9_sC4K6lbG7vkP2bPeUmtxiLCPEfF5kgEF20Sdk9c7mnuQ2bwvuKM; path=/; expires=Fri, 21-Nov-25 11:15:25 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=w5q4FmaqcdwAJQ1YOVUIEQ5aNpzTc1R0wjGpVV8yAME-1763721925857-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '249'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '262'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_1cc1d1c68c624dfd9ec380402ebdb182
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1f98f20dc5d2bf-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:45:25 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=_VG8TZ8A7B5ZJgfRcE4YsCLWQj3koQ15K2UpjIA8jIU-1763721925-1.0.1.1-EmM6jA8RGyK4ijrUCclE0QgSaM78wQJZQ4uAvj6Nmj4slQVL1DSSVP9_sC4K6lbG7vkP2bPeUmtxiLCPEfF5kgEF20Sdk9c7mnuQ2bwvuKM; path=/; expires=Fri, 21-Nov-25 11:15:25 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=w5q4FmaqcdwAJQ1YOVUIEQ5aNpzTc1R0wjGpVV8yAME-1763721925857-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '249'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '262'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_1cc1d1c68c624dfd9ec380402ebdb182
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: 'data: {"id":"chatcmpl-CeIxHuRyBsltIxBO6imrmsMeY4kji","object":"chat.completion.chunk","created":1763722019,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"role":"assistant","content":"","refusal":null},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"FKMVGFX0"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIxHuRyBsltIxBO6imrmsMeY4kji","object":"chat.completion.chunk","created":1763722019,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"Lite"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"MQtynO"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIxHuRyBsltIxBO6imrmsMeY4kji","object":"chat.completion.chunk","created":1763722019,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"LL"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"TiXS7u89"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIxHuRyBsltIxBO6imrmsMeY4kji","object":"chat.completion.chunk","created":1763722019,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"M"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"LbCkUsZmk"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIxHuRyBsltIxBO6imrmsMeY4kji","object":"chat.completion.chunk","created":1763722019,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" streaming"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":""} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIxHuRyBsltIxBO6imrmsMeY4kji","object":"chat.completion.chunk","created":1763722019,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" works"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"fIg9"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIxHuRyBsltIxBO6imrmsMeY4kji","object":"chat.completion.chunk","created":1763722019,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"!"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"j93pCBZe3"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIxHuRyBsltIxBO6imrmsMeY4kji","object":"chat.completion.chunk","created":1763722019,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}],"usage":null,"obfuscation":"pyXB"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIxHuRyBsltIxBO6imrmsMeY4kji","object":"chat.completion.chunk","created":1763722019,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[],"usage":{"prompt_tokens":18,"completion_tokens":6,"total_tokens":24,"prompt_tokens_details":{"cached_tokens":0,"audio_tokens":0},"completion_tokens_details":{"reasoning_tokens":0,"audio_tokens":0,"accepted_prediction_tokens":0,"rejected_prediction_tokens":0}},"obfuscation":"AOgPzL6oA3"} #magic___^_^___line #magic___^_^___line data: [DONE] #magic___^_^___line #magic___^_^___line '
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1f9b3da9edd3a9-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:46:59 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=vatTWmXzraxxmIE9gGwbCKvFcVWrr04NDRhpfg_lPDs-1763722019-1.0.1.1-nvddVawnYQeIVnug7I8ykq1OOTjbxEh7QCnhKVaLSPoQafAZx9G.7wG_lJFE._NS9qMbY82u1Y8kUDydaeHdemaBavMR9BR95.9i6ZWiicY; path=/; expires=Fri, 21-Nov-25 11:16:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=r9wxhaGh8DwfSSl_cVQP5ridIQ__dHuGAUEG.d9Ph.A-1763722019893-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '263'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '277'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '498'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 128ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_e53a7fda311841c3b7aa88dfa56527fd
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1f9b3da9edd3a9-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:46:59 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=vatTWmXzraxxmIE9gGwbCKvFcVWrr04NDRhpfg_lPDs-1763722019-1.0.1.1-nvddVawnYQeIVnug7I8ykq1OOTjbxEh7QCnhKVaLSPoQafAZx9G.7wG_lJFE._NS9qMbY82u1Y8kUDydaeHdemaBavMR9BR95.9i6ZWiicY; path=/; expires=Fri, 21-Nov-25 11:16:59 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=r9wxhaGh8DwfSSl_cVQP5ridIQ__dHuGAUEG.d9Ph.A-1763722019893-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '263'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '277'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '498'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 128ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_e53a7fda311841c3b7aa88dfa56527fd
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: 'data: {"id":"chatcmpl-CeIz3j2ENOiHAhXrXSUefJRe3hRAr","object":"chat.completion.chunk","created":1763722129,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"role":"assistant","content":"","refusal":null},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"Dz16LCeD"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIz3j2ENOiHAhXrXSUefJRe3hRAr","object":"chat.completion.chunk","created":1763722129,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"Lite"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"lbp2Ru"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIz3j2ENOiHAhXrXSUefJRe3hRAr","object":"chat.completion.chunk","created":1763722129,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"LL"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"clQRF2Tz"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIz3j2ENOiHAhXrXSUefJRe3hRAr","object":"chat.completion.chunk","created":1763722129,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"M"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"5RSmDjyNI"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIz3j2ENOiHAhXrXSUefJRe3hRAr","object":"chat.completion.chunk","created":1763722129,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" streaming"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":""} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIz3j2ENOiHAhXrXSUefJRe3hRAr","object":"chat.completion.chunk","created":1763722129,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" works"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"bENN"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIz3j2ENOiHAhXrXSUefJRe3hRAr","object":"chat.completion.chunk","created":1763722129,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"!"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"LUpGy7jqw"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIz3j2ENOiHAhXrXSUefJRe3hRAr","object":"chat.completion.chunk","created":1763722129,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}],"usage":null,"obfuscation":"ijTK"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeIz3j2ENOiHAhXrXSUefJRe3hRAr","object":"chat.completion.chunk","created":1763722129,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[],"usage":{"prompt_tokens":18,"completion_tokens":6,"total_tokens":24,"prompt_tokens_details":{"cached_tokens":0,"audio_tokens":0},"completion_tokens_details":{"reasoning_tokens":0,"audio_tokens":0,"accepted_prediction_tokens":0,"rejected_prediction_tokens":0}},"obfuscation":"bqvVU9NdCP"} #magic___^_^___line #magic___^_^___line data: [DONE] #magic___^_^___line #magic___^_^___line '
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1f9dea4fc0d9d3-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:48:49 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=OLd7MssxbQJyUq5.JDoTbG0V.111EcGUJgLaYJdbfsM-1763722129-1.0.1.1-Z09Wn7NqKU8UaSw_j1CfGioCiKEmWwIbj1H9AJjFRlr5JTcenhhpUgseQKsfvtSmlGf8JaKGUysrbtR7jOggkSQcByCHPNgNU1j4CnooLgw; path=/; expires=Fri, 21-Nov-25 11:18:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=_Ec_kzl6ImHE5mBjH_3TcZJkd16l8fL7T._0jajMh94-1763722129426-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '235'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '247'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_3a2510b6eddb4e0eb3fea5d93adb26b2
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1f9dea4fc0d9d3-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:48:49 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=OLd7MssxbQJyUq5.JDoTbG0V.111EcGUJgLaYJdbfsM-1763722129-1.0.1.1-Z09Wn7NqKU8UaSw_j1CfGioCiKEmWwIbj1H9AJjFRlr5JTcenhhpUgseQKsfvtSmlGf8JaKGUysrbtR7jOggkSQcByCHPNgNU1j4CnooLgw; path=/; expires=Fri, 21-Nov-25 11:18:49 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=_Ec_kzl6ImHE5mBjH_3TcZJkd16l8fL7T._0jajMh94-1763722129426-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '235'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '247'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_3a2510b6eddb4e0eb3fea5d93adb26b2
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: 'data: {"id":"chatcmpl-CeJ04l8LXLHYR1gay8ZqadYVwwbes","object":"chat.completion.chunk","created":1763722192,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"role":"assistant","content":"","refusal":null},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"BfiSfizO"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ04l8LXLHYR1gay8ZqadYVwwbes","object":"chat.completion.chunk","created":1763722192,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"Lite"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"Fxej5m"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ04l8LXLHYR1gay8ZqadYVwwbes","object":"chat.completion.chunk","created":1763722192,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"LL"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"RCmKBXKd"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ04l8LXLHYR1gay8ZqadYVwwbes","object":"chat.completion.chunk","created":1763722192,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"M"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"PgBNuTsgh"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ04l8LXLHYR1gay8ZqadYVwwbes","object":"chat.completion.chunk","created":1763722192,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" streaming"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":""} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ04l8LXLHYR1gay8ZqadYVwwbes","object":"chat.completion.chunk","created":1763722192,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" works"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"7jlE"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ04l8LXLHYR1gay8ZqadYVwwbes","object":"chat.completion.chunk","created":1763722192,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"!"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"2T0Aw9tdd"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ04l8LXLHYR1gay8ZqadYVwwbes","object":"chat.completion.chunk","created":1763722192,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}],"usage":null,"obfuscation":"xNQd"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ04l8LXLHYR1gay8ZqadYVwwbes","object":"chat.completion.chunk","created":1763722192,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[],"usage":{"prompt_tokens":18,"completion_tokens":6,"total_tokens":24,"prompt_tokens_details":{"cached_tokens":0,"audio_tokens":0},"completion_tokens_details":{"reasoning_tokens":0,"audio_tokens":0,"accepted_prediction_tokens":0,"rejected_prediction_tokens":0}},"obfuscation":"Wkm6Doh5jB"} #magic___^_^___line #magic___^_^___line data: [DONE] #magic___^_^___line #magic___^_^___line '
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1f9f780958365c-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:49:53 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=8RvXXx6GKqDlS89WRfP6R2sroUIDSqvkrTT.p9fc15Y-1763722193-1.0.1.1-UD4hkLAopA2wXNlUBP2Mlkvq_2tvZll5Ro7blYFj9SzcbekxFKS1M4WMxyEY.OzDbez4JXqa0V04ixv5ddGB_nQDoRwGH7RHywdq0wxvaaY; path=/; expires=Fri, 21-Nov-25 11:19:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=c0Jt92opix8PCcWZB.j58QOKn0GpzD7Q.MkXZp1LoHo-1763722193158-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '338'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '359'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_dba059a77d0247e78a0c31c0324e5f34
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1f9f780958365c-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:49:53 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=8RvXXx6GKqDlS89WRfP6R2sroUIDSqvkrTT.p9fc15Y-1763722193-1.0.1.1-UD4hkLAopA2wXNlUBP2Mlkvq_2tvZll5Ro7blYFj9SzcbekxFKS1M4WMxyEY.OzDbez4JXqa0V04ixv5ddGB_nQDoRwGH7RHywdq0wxvaaY; path=/; expires=Fri, 21-Nov-25 11:19:53 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=c0Jt92opix8PCcWZB.j58QOKn0GpzD7Q.MkXZp1LoHo-1763722193158-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '338'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '359'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_dba059a77d0247e78a0c31c0324e5f34
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: 'data: {"id":"chatcmpl-CeJ1GRsTxjlZJcaphdXUDBvvdIjrG","object":"chat.completion.chunk","created":1763722266,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"role":"assistant","content":"","refusal":null},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"R8U21JYQ"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ1GRsTxjlZJcaphdXUDBvvdIjrG","object":"chat.completion.chunk","created":1763722266,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"Lite"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"CgjBKV"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ1GRsTxjlZJcaphdXUDBvvdIjrG","object":"chat.completion.chunk","created":1763722266,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"LL"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"DReRweC2"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ1GRsTxjlZJcaphdXUDBvvdIjrG","object":"chat.completion.chunk","created":1763722266,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"M"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"DWmmMi4Ni"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ1GRsTxjlZJcaphdXUDBvvdIjrG","object":"chat.completion.chunk","created":1763722266,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" streaming"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":""} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ1GRsTxjlZJcaphdXUDBvvdIjrG","object":"chat.completion.chunk","created":1763722266,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" works"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"PIKV"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ1GRsTxjlZJcaphdXUDBvvdIjrG","object":"chat.completion.chunk","created":1763722266,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"!"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"9qRF3OIkH"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ1GRsTxjlZJcaphdXUDBvvdIjrG","object":"chat.completion.chunk","created":1763722266,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}],"usage":null,"obfuscation":"eOjc"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ1GRsTxjlZJcaphdXUDBvvdIjrG","object":"chat.completion.chunk","created":1763722266,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[],"usage":{"prompt_tokens":18,"completion_tokens":6,"total_tokens":24,"prompt_tokens_details":{"cached_tokens":0,"audio_tokens":0},"completion_tokens_details":{"reasoning_tokens":0,"audio_tokens":0,"accepted_prediction_tokens":0,"rejected_prediction_tokens":0}},"obfuscation":"6sefpQI01X"} #magic___^_^___line #magic___^_^___line data: [DONE] #magic___^_^___line #magic___^_^___line '
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1fa142487ed22f-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:51:07 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=CPDDGkdjrjQttJBjtP3Gw9sD2Lme1Y_YU.KIb9aBSrE-1763722267-1.0.1.1-td1HYaFXQG8.wydxQNC1P_YyvXDFDUgehmKdZ3kyPn3WYmAuJoVh01Sg1zvBl33uVZOoZ0fbsUujo4YOl24oVPYxooaTEGkAYInFzWVydR4; path=/; expires=Fri, 21-Nov-25 11:21:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=GcF2LcEftNFD4CFBGynb29eBlm4SxGGSiLrUawvh9Hc-1763722267053-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '719'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '910'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_834b8dee6eaf4164948a5bf9e3a98e0c
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1fa142487ed22f-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:51:07 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=CPDDGkdjrjQttJBjtP3Gw9sD2Lme1Y_YU.KIb9aBSrE-1763722267-1.0.1.1-td1HYaFXQG8.wydxQNC1P_YyvXDFDUgehmKdZ3kyPn3WYmAuJoVh01Sg1zvBl33uVZOoZ0fbsUujo4YOl24oVPYxooaTEGkAYInFzWVydR4; path=/; expires=Fri, 21-Nov-25 11:21:07 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=GcF2LcEftNFD4CFBGynb29eBlm4SxGGSiLrUawvh9Hc-1763722267053-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '719'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '910'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_834b8dee6eaf4164948a5bf9e3a98e0c
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: 'data: {"id":"chatcmpl-CeJ25Knn6M2z59dtkQQYqZPKbJtRG","object":"chat.completion.chunk","created":1763722317,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"role":"assistant","content":"","refusal":null},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"fxZhMrhG"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ25Knn6M2z59dtkQQYqZPKbJtRG","object":"chat.completion.chunk","created":1763722317,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"Lite"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"bgPEc8"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ25Knn6M2z59dtkQQYqZPKbJtRG","object":"chat.completion.chunk","created":1763722317,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"LL"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"fZei68bQ"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ25Knn6M2z59dtkQQYqZPKbJtRG","object":"chat.completion.chunk","created":1763722317,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"M"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"Z19IvCpk7"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ25Knn6M2z59dtkQQYqZPKbJtRG","object":"chat.completion.chunk","created":1763722317,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" streaming"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":""} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ25Knn6M2z59dtkQQYqZPKbJtRG","object":"chat.completion.chunk","created":1763722317,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" works"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"UtUI"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ25Knn6M2z59dtkQQYqZPKbJtRG","object":"chat.completion.chunk","created":1763722317,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"!"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"1dnwzKJuD"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ25Knn6M2z59dtkQQYqZPKbJtRG","object":"chat.completion.chunk","created":1763722317,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}],"usage":null,"obfuscation":"AcbF"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ25Knn6M2z59dtkQQYqZPKbJtRG","object":"chat.completion.chunk","created":1763722317,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[],"usage":{"prompt_tokens":18,"completion_tokens":6,"total_tokens":24,"prompt_tokens_details":{"cached_tokens":0,"audio_tokens":0},"completion_tokens_details":{"reasoning_tokens":0,"audio_tokens":0,"accepted_prediction_tokens":0,"rejected_prediction_tokens":0}},"obfuscation":"eAxH3nTDgX"} #magic___^_^___line #magic___^_^___line data: [DONE] #magic___^_^___line #magic___^_^___line '
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1fa281be3b30ea-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:51:57 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=dhgYEgJDYKEX2w5cgnP_c8lgUwgEOSBJV5emAr7LTTI-1763722317-1.0.1.1-jbpgol.6YiZqslLbY3iO..niSuU0.ilRI84iCLC_lvZXtwf01GEOFoRcmGw1Ca2eRT1W6VH0vWC61hPfCbtQABUgiG17AHi2.bUonZqVXHk; path=/; expires=Fri, 21-Nov-25 11:21:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=9MwmnutMQm9ZiWZMKyyuN8ibepNUBXv3yeuZgGiJbUE-1763722317488-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '228'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '241'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_e6f7db5295ec455b9a1389f529389d37
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1fa281be3b30ea-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:51:57 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=dhgYEgJDYKEX2w5cgnP_c8lgUwgEOSBJV5emAr7LTTI-1763722317-1.0.1.1-jbpgol.6YiZqslLbY3iO..niSuU0.ilRI84iCLC_lvZXtwf01GEOFoRcmGw1Ca2eRT1W6VH0vWC61hPfCbtQABUgiG17AHi2.bUonZqVXHk; path=/; expires=Fri, 21-Nov-25 11:21:57 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=9MwmnutMQm9ZiWZMKyyuN8ibepNUBXv3yeuZgGiJbUE-1763722317488-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '228'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '241'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_e6f7db5295ec455b9a1389f529389d37
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: 'data: {"id":"chatcmpl-CeJ4IpAd1NQx1PBXt3eW5FgdLcXp4","object":"chat.completion.chunk","created":1763722454,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"role":"assistant","content":"","refusal":null},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"AkqIrDA0"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ4IpAd1NQx1PBXt3eW5FgdLcXp4","object":"chat.completion.chunk","created":1763722454,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"Lite"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"XaIM8u"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ4IpAd1NQx1PBXt3eW5FgdLcXp4","object":"chat.completion.chunk","created":1763722454,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"LL"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"75mek24E"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ4IpAd1NQx1PBXt3eW5FgdLcXp4","object":"chat.completion.chunk","created":1763722454,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"M"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"YFMs7lwMH"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ4IpAd1NQx1PBXt3eW5FgdLcXp4","object":"chat.completion.chunk","created":1763722454,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" streaming"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":""} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ4IpAd1NQx1PBXt3eW5FgdLcXp4","object":"chat.completion.chunk","created":1763722454,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" works"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"TjWP"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ4IpAd1NQx1PBXt3eW5FgdLcXp4","object":"chat.completion.chunk","created":1763722454,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"!"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"48t1VZr03"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ4IpAd1NQx1PBXt3eW5FgdLcXp4","object":"chat.completion.chunk","created":1763722454,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}],"usage":null,"obfuscation":"vjB7"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ4IpAd1NQx1PBXt3eW5FgdLcXp4","object":"chat.completion.chunk","created":1763722454,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[],"usage":{"prompt_tokens":18,"completion_tokens":6,"total_tokens":24,"prompt_tokens_details":{"cached_tokens":0,"audio_tokens":0},"completion_tokens_details":{"reasoning_tokens":0,"audio_tokens":0,"accepted_prediction_tokens":0,"rejected_prediction_tokens":0}},"obfuscation":"pt8x71xE3E"} #magic___^_^___line #magic___^_^___line data: [DONE] #magic___^_^___line #magic___^_^___line '
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1fa5da39924d4f-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:54:14 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=WJW0KIjkHbUW1QkwuaJmrsG5N0L6wOB6z2UbYvfL0Wk-1763722454-1.0.1.1-Yu64b5ShuXbHKR1mxstrenPQlI8ScAk9lknGd4GlxHpnnhsOq0JdGDiayqMTfb7nE83.5OerwF_ZaLkPBzMPfypmisPZEpFnGDZkGefRcQQ; path=/; expires=Fri, 21-Nov-25 11:24:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=bTJxDqnJUNgXeSHiVihhjiEnQ273pwjPrqjHAk0zBz8-1763722454540-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '231'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '244'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_dd1861bb110e4f5cbf795f396b8f3e10
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1fa5da39924d4f-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:54:14 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=WJW0KIjkHbUW1QkwuaJmrsG5N0L6wOB6z2UbYvfL0Wk-1763722454-1.0.1.1-Yu64b5ShuXbHKR1mxstrenPQlI8ScAk9lknGd4GlxHpnnhsOq0JdGDiayqMTfb7nE83.5OerwF_ZaLkPBzMPfypmisPZEpFnGDZkGefRcQQ; path=/; expires=Fri, 21-Nov-25 11:24:14 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=bTJxDqnJUNgXeSHiVihhjiEnQ273pwjPrqjHAk0zBz8-1763722454540-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '231'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '244'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_dd1861bb110e4f5cbf795f396b8f3e10
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano"}'
      headers:
        Cookie:
          - __cf_bm=WJW0KIjkHbUW1QkwuaJmrsG5N0L6wOB6z2UbYvfL0Wk-1763722454-1.0.1.1-Yu64b5ShuXbHKR1mxstrenPQlI8ScAk9lknGd4GlxHpnnhsOq0JdGDiayqMTfb7nE83.5OerwF_ZaLkPBzMPfypmisPZEpFnGDZkGefRcQQ; _cfuvid=bTJxDqnJUNgXeSHiVihhjiEnQ273pwjPrqjHAk0zBz8-1763722454540-0.0.1.1-604800000
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '112'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: !!binary |
          H4sIAAAAAAAAAwAAAP//jFLLbtswELzrK1iercBSZDv11WiBBk4PRW9FIKyplcSY4hLkKk0R+N8L
          So6lPAr0osPOzmhmuM+JEFJXciukaoFV50y6w9vi267fLfvu5/rp6O427erLd1Ooh68/buQiMujw
          gIpfWFeKOmeQNdkRVh6BMapmm/X1Js+LVTEAHVVoIq1xnBZXWWrBUpov81W6LNKsONNb0gqD3Ipf
          iRBCPA/faNRW+CS3Yrl4mXQYAjQot5clIaQnEycSQtCBwbJcTKAiy2gH73vNuN/ficAeodO2Eb/J
          H8On+brHug8QPdvemBkA1hJDzDwYvT8jp4s1Q43zdAhvqLLWVoe29AiBbLQRmJwc0FMixP1QQf8q
          lXSeOscl0xGH32U3o5ycmp/A9RljYjDTOC8WH4iVFTJoE2YNSgWqxWpiTnVDX2maAcks8nsvH2mP
          sbVt/kd+ApRCx1iVzmOl1eu805rHeJb/WrtUPBiWAf2jVliyRh+focIaejPeigx/AmNX1to26J3X
          48HUrszg8+awAlgrmZySvwAAAP//AwBGQExsPwMAAA==
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1fa5dd6bc24d4f-FRA
        Connection:
          - keep-alive
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json
        Date:
          - Fri, 21 Nov 2025 10:54:15 GMT
        Server:
          - cloudflare
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '293'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '310'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_2d9ec7f5893e4ce5acf46cdf4d895f29
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano"}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '112'
        content-type:
          - application/json
        cookie:
          - __cf_bm=WJW0KIjkHbUW1QkwuaJmrsG5N0L6wOB6z2UbYvfL0Wk-1763722454-1.0.1.1-Yu64b5ShuXbHKR1mxstrenPQlI8ScAk9lknGd4GlxHpnnhsOq0JdGDiayqMTfb7nE83.5OerwF_ZaLkPBzMPfypmisPZEpFnGDZkGefRcQQ; _cfuvid=bTJxDqnJUNgXeSHiVihhjiEnQ273pwjPrqjHAk0zBz8-1763722454540-0.0.1.1-604800000
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1fa5dd6bc24d4f-FRA
        Connection:
          - keep-alive
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json
        Date:
          - Fri, 21 Nov 2025 10:54:15 GMT
        Server:
          - cloudflare
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '293'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '310'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_2d9ec7f5893e4ce5acf46cdf4d895f29
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: 'data: {"id":"chatcmpl-CeJ5CS6SHF1WJFcS32vyhIAfsdaLx","object":"chat.completion.chunk","created":1763722510,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"role":"assistant","content":"","refusal":null},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"rwrCGXEC"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ5CS6SHF1WJFcS32vyhIAfsdaLx","object":"chat.completion.chunk","created":1763722510,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"Lite"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"jRfyR5"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ5CS6SHF1WJFcS32vyhIAfsdaLx","object":"chat.completion.chunk","created":1763722510,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"LL"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"d6MajAFk"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ5CS6SHF1WJFcS32vyhIAfsdaLx","object":"chat.completion.chunk","created":1763722510,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"M"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"NXapD8ucQ"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ5CS6SHF1WJFcS32vyhIAfsdaLx","object":"chat.completion.chunk","created":1763722510,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" streaming"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":""} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ5CS6SHF1WJFcS32vyhIAfsdaLx","object":"chat.completion.chunk","created":1763722510,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" works"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"LvTK"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ5CS6SHF1WJFcS32vyhIAfsdaLx","object":"chat.completion.chunk","created":1763722510,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"!"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"0nN1WxgZb"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ5CS6SHF1WJFcS32vyhIAfsdaLx","object":"chat.completion.chunk","created":1763722510,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}],"usage":null,"obfuscation":"OASf"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeJ5CS6SHF1WJFcS32vyhIAfsdaLx","object":"chat.completion.chunk","created":1763722510,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[],"usage":{"prompt_tokens":18,"completion_tokens":6,"total_tokens":24,"prompt_tokens_details":{"cached_tokens":0,"audio_tokens":0},"completion_tokens_details":{"reasoning_tokens":0,"audio_tokens":0,"accepted_prediction_tokens":0,"rejected_prediction_tokens":0}},"obfuscation":"3lutWQhO4O"} #magic___^_^___line #magic___^_^___line data: [DONE] #magic___^_^___line #magic___^_^___line '
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1fa7393e56d22a-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:55:10 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=yo_ByZsxL6v69zT_xzBIEcZNjn.RH98CN5ITXdVW1oA-1763722510-1.0.1.1-69p7kGXgiK3wkwxeY94eX1lYc7i4poMLWd.8r6OgZ9H0vr7sX9DAQFxrus_QOcRJEukKtHoAR1heLg422uuLnx254TwzZ7gdIfAusKfSaBk; path=/; expires=Fri, 21-Nov-25 11:25:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=p5.6N0vn7ZxlAz2aR1K4OAYgMkgvDwE6MeZIfaktah8-1763722510692-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '246'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '263'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_1d923c3980264e82b90d52a57b9855b9
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1fa7393e56d22a-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 10:55:10 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=yo_ByZsxL6v69zT_xzBIEcZNjn.RH98CN5ITXdVW1oA-1763722510-1.0.1.1-69p7kGXgiK3wkwxeY94eX1lYc7i4poMLWd.8r6OgZ9H0vr7sX9DAQFxrus_QOcRJEukKtHoAR1heLg422uuLnx254TwzZ7gdIfAusKfSaBk; path=/; expires=Fri, 21-Nov-25 11:25:10 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=p5.6N0vn7ZxlAz2aR1K4OAYgMkgvDwE6MeZIfaktah8-1763722510692-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '246'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '263'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_1d923c3980264e82b90d52a57b9855b9
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano"}'
      headers:
        Cookie:
          - __cf_bm=yo_ByZsxL6v69zT_xzBIEcZNjn.RH98CN5ITXdVW1oA-1763722510-1.0.1.1-69p7kGXgiK3wkwxeY94eX1lYc7i4poMLWd.8r6OgZ9H0vr7sX9DAQFxrus_QOcRJEukKtHoAR1heLg422uuLnx254TwzZ7gdIfAusKfSaBk; _cfuvid=p5.6N0vn7ZxlAz2aR1K4OAYgMkgvDwE6MeZIfaktah8-1763722510692-0.0.1.1-604800000
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '112'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: !!binary |
          H4sIAAAAAAAAAwAAAP//jFJBbtswELzrFSzPViAplt34GN8cu2gvTdEiENbUSmZCkQS5alIE/ntB
          yrWUJgFy0WFnZzQz3OeEMS5rvmJcHIBEZ1W6xk25/na7230vHjfXlz822e7pS3n/8+Zrtr7ls8Aw
          +3sU9I91IUxnFZI0eoCFQyAMqvlycbksijLPItCZGlWgtZbS+UWeatAmLbKiTLN5ms9P9IORAj1f
          sV8JY4w9x28wqmt84isWxeKkQ++hRb46LzHGnVFhwsF76Qk08dkICqMJdfS+lYTb7Y55cgid1C17
          NO7Bf5quO2x6D8Gz7pWaAKC1IQiZo9G7E3I8W1Omtc7s/X9U3kgt/aFyCN7oYMOTsTyix4Sxu1hB
          /yIVt850lioyDxh/l38e5PjY/AguThgZAjWOi/nsDbGqRgKp/KRBLkAcsB6ZY93Q19JMgGQS+bWX
          t7SH2FK3H5EfASHQEtaVdVhL8TLvuOYwnOV7a+eKo2Hu0f2WAiuS6MIz1NhAr4Zb4f6PJ+yqRuoW
          nXVyOJjGVjlcLfclwELw5Jj8BQAA//8DACuNrHs/AwAA
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1fa73c6deed22a-FRA
        Connection:
          - keep-alive
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json
        Date:
          - Fri, 21 Nov 2025 10:55:11 GMT
        Server:
          - cloudflare
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '330'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '344'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_fa994f49082b47e49e5e884a431e1d8c
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano"}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '112'
        content-type:
          - application/json
        cookie:
          - __cf_bm=yo_ByZsxL6v69zT_xzBIEcZNjn.RH98CN5ITXdVW1oA-1763722510-1.0.1.1-69p7kGXgiK3wkwxeY94eX1lYc7i4poMLWd.8r6OgZ9H0vr7sX9DAQFxrus_QOcRJEukKtHoAR1heLg422uuLnx254TwzZ7gdIfAusKfSaBk; _cfuvid=p5.6N0vn7ZxlAz2aR1K4OAYgMkgvDwE6MeZIfaktah8-1763722510692-0.0.1.1-604800000
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a1fa73c6deed22a-FRA
        Connection:
          - keep-alive
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json
        Date:
          - Fri, 21 Nov 2025 10:55:11 GMT
        Server:
          - cloudflare
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '330'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '344'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_fa994f49082b47e49e5e884a431e1d8c
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: 'data: {"id":"chatcmpl-CeK8EfRrY2zMsblHpsOxATA9SWJV6","object":"chat.completion.chunk","created":1763726542,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"role":"assistant","content":"","refusal":null},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"b4kczUw7"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeK8EfRrY2zMsblHpsOxATA9SWJV6","object":"chat.completion.chunk","created":1763726542,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"Lite"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"igVa7d"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeK8EfRrY2zMsblHpsOxATA9SWJV6","object":"chat.completion.chunk","created":1763726542,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"LL"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"kN4pf1MR"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeK8EfRrY2zMsblHpsOxATA9SWJV6","object":"chat.completion.chunk","created":1763726542,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"M"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"1zB0jZCpu"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeK8EfRrY2zMsblHpsOxATA9SWJV6","object":"chat.completion.chunk","created":1763726542,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" streaming"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":""} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeK8EfRrY2zMsblHpsOxATA9SWJV6","object":"chat.completion.chunk","created":1763726542,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" works"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"kXLo"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeK8EfRrY2zMsblHpsOxATA9SWJV6","object":"chat.completion.chunk","created":1763726542,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"!"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"I9VwnyXmZ"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeK8EfRrY2zMsblHpsOxATA9SWJV6","object":"chat.completion.chunk","created":1763726542,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}],"usage":null,"obfuscation":"dAV0"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeK8EfRrY2zMsblHpsOxATA9SWJV6","object":"chat.completion.chunk","created":1763726542,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[],"usage":{"prompt_tokens":18,"completion_tokens":6,"total_tokens":24,"prompt_tokens_details":{"cached_tokens":0,"audio_tokens":0},"completion_tokens_details":{"reasoning_tokens":0,"audio_tokens":0,"accepted_prediction_tokens":0,"rejected_prediction_tokens":0}},"obfuscation":"Euwxv216qb"} #magic___^_^___line #magic___^_^___line data: [DONE] #magic___^_^___line #magic___^_^___line '
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a2009a57a3f5d45-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 12:02:22 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=pKrSaISXovHyG38K.BMAyCPketuLtLewkg.nb0dde3U-1763726542-1.0.1.1-RGaihjIhRi6ksLyDVws5Ymxq7mdMaguf7IGSy4YC6.hSan9zLJiDr4Uu33mC_ceHxewlDBuIjaJdfnxA_uEKyj_XBkEHkyfnBebCfNuic70; path=/; expires=Fri, 21-Nov-25 12:32:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=.Yot1HNl04FuCIPZnNg2yfzEJALegidI9OihqAZAezg-1763726542858-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '223'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '373'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_9d77ed45c06d49cab080499ee0d0a089
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a2009a57a3f5d45-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 12:02:22 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=pKrSaISXovHyG38K.BMAyCPketuLtLewkg.nb0dde3U-1763726542-1.0.1.1-RGaihjIhRi6ksLyDVws5Ymxq7mdMaguf7IGSy4YC6.hSan9zLJiDr4Uu33mC_ceHxewlDBuIjaJdfnxA_uEKyj_XBkEHkyfnBebCfNuic70; path=/; expires=Fri, 21-Nov-25 12:32:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=.Yot1HNl04FuCIPZnNg2yfzEJALegidI9OihqAZAezg-1763726542858-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '223'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '373'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_9d77ed45c06d49cab080499ee0d0a089
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano"}'
      headers:
        Cookie:
          - __cf_bm=pKrSaISXovHyG38K.BMAyCPketuLtLewkg.nb0dde3U-1763726542-1.0.1.1-RGaihjIhRi6ksLyDVws5Ymxq7mdMaguf7IGSy4YC6.hSan9zLJiDr4Uu33mC_ceHxewlDBuIjaJdfnxA_uEKyj_XBkEHkyfnBebCfNuic70; _cfuvid=.Yot1HNl04FuCIPZnNg2yfzEJALegidI9OihqAZAezg-1763726542858-0.0.1.1-604800000
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '112'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: !!binary |
          H4sIAAAAAAAAAwAAAP//jFJBbtswELzrFeyercByZDvxtU2Ati7aU4CiCIQ1uZIZUyRLrtIWgf9e
          UHIspU2BXnTY2RnNDPcpEwK0go0AuUeWrTf5W/p4dXtzKNX198/2ztTq7ssjhne7cPPh/VeYJYbb
          PZDkZ9aFdK03xNrZAZaBkCmpFuvV5XqxWpaXPdA6RSbRGs95eVHkFq3LF/PFMp+XeVGe6HunJUXY
          iG+ZEEI89d9k1Cr6CRsxnz1PWooRG4LNeUkICM6kCWCMOjJahtkISmeZbO99q5m2208iciBstW3E
          DxcO8c10PVDdRUyebWfMBEBrHWPK3Bu9PyHHszXjGh/cLv5BhVpbHfdVIIzOJhuRnYcePWZC3PcV
          dC9SgQ+u9VyxO1D/u+JqkIOx+RFcnTB2jGYcL8rZK2KVIkZt4qRBkCj3pEbmWDd2SrsJkE0i/+3l
          Ne0htrbN/8iPgJTkmVTlAyktX+Yd1wKls/zX2rni3jBECo9aUsWaQnoGRTV2ZrgViL8iU1vV2jYU
          fNDDwdS+KvB6vVsiriRkx+w3AAAA//8DALwRLY0/AwAA
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a2009ad8fc65d45-FRA
        Connection:
          - keep-alive
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json
        Date:
          - Fri, 21 Nov 2025 12:02:23 GMT
        Server:
          - cloudflare
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '312'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '324'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_e98effa6e45148afa86fbe3e457ee96e
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano"}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '112'
        content-type:
          - application/json
        cookie:
          - __cf_bm=pKrSaISXovHyG38K.BMAyCPketuLtLewkg.nb0dde3U-1763726542-1.0.1.1-RGaihjIhRi6ksLyDVws5Ymxq7mdMaguf7IGSy4YC6.hSan9zLJiDr4Uu33mC_ceHxewlDBuIjaJdfnxA_uEKyj_XBkEHkyfnBebCfNuic70; _cfuvid=.Yot1HNl04FuCIPZnNg2yfzEJALegidI9OihqAZAezg-1763726542858-0.0.1.1-604800000
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a2009ad8fc65d45-FRA
        Connection:
          - keep-alive
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json
        Date:
          - Fri, 21 Nov 2025 12:02:23 GMT
        Server:
          - cloudflare
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '312'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '324'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_e98effa6e45148afa86fbe3e457ee96e
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: 'data: {"id":"chatcmpl-CeKu0fGLIvcUQpWcW3ekumBo082N9","object":"chat.completion.chunk","created":1763729504,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"role":"assistant","content":"","refusal":null},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"NtTBN7Fw"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeKu0fGLIvcUQpWcW3ekumBo082N9","object":"chat.completion.chunk","created":1763729504,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"Lite"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"xKYMn8"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeKu0fGLIvcUQpWcW3ekumBo082N9","object":"chat.completion.chunk","created":1763729504,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"LL"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"UuNnBtUk"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeKu0fGLIvcUQpWcW3ekumBo082N9","object":"chat.completion.chunk","created":1763729504,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"M"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"Yf7DMg4iK"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeKu0fGLIvcUQpWcW3ekumBo082N9","object":"chat.completion.chunk","created":1763729504,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" streaming"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":""} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeKu0fGLIvcUQpWcW3ekumBo082N9","object":"chat.completion.chunk","created":1763729504,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" works"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"cgTh"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeKu0fGLIvcUQpWcW3ekumBo082N9","object":"chat.completion.chunk","created":1763729504,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"!"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"kjsMa9ix3"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeKu0fGLIvcUQpWcW3ekumBo082N9","object":"chat.completion.chunk","created":1763729504,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}],"usage":null,"obfuscation":"zNhY"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeKu0fGLIvcUQpWcW3ekumBo082N9","object":"chat.completion.chunk","created":1763729504,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[],"usage":{"prompt_tokens":18,"completion_tokens":6,"total_tokens":24,"prompt_tokens_details":{"cached_tokens":0,"audio_tokens":0},"completion_tokens_details":{"reasoning_tokens":0,"audio_tokens":0,"accepted_prediction_tokens":0,"rejected_prediction_tokens":0}},"obfuscation":"RpyBZcGsQd"} #magic___^_^___line #magic___^_^___line data: [DONE] #magic___^_^___line #magic___^_^___line '
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a2051f6dd2f0686-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 12:51:44 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=KKuUVoq9Ic02.CdjaNifcZ8Ggd2pK2wENnupadYC0is-1763729504-1.0.1.1-ksfxEDxXX8HGwiWvYzaLmgK6NO4WmO8g6l9PrZiyjBQ7ehAoiS63Yxk8R9iVWgsgoDdqW2cmjn55fURvOFIusfpUd0r6IjYBSQctbyrYFkI; path=/; expires=Fri, 21-Nov-25 13:21:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=G6jGA0d5Se4ghygETAgNPPALR34SaJOHHv_mM2q2WB4-1763729504384-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '243'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '392'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_11e96516676f41fc84b22b0493355b81
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a2051f6dd2f0686-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Fri, 21 Nov 2025 12:51:44 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=KKuUVoq9Ic02.CdjaNifcZ8Ggd2pK2wENnupadYC0is-1763729504-1.0.1.1-ksfxEDxXX8HGwiWvYzaLmgK6NO4WmO8g6l9PrZiyjBQ7ehAoiS63Yxk8R9iVWgsgoDdqW2cmjn55fURvOFIusfpUd0r6IjYBSQctbyrYFkI; path=/; expires=Fri, 21-Nov-25 13:21:44 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=G6jGA0d5Se4ghygETAgNPPALR34SaJOHHv_mM2q2WB4-1763729504384-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '243'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '392'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_11e96516676f41fc84b22b0493355b81
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano"}'
      headers:
        Cookie:
          - __cf_bm=KKuUVoq9Ic02.CdjaNifcZ8Ggd2pK2wENnupadYC0is-1763729504-1.0.1.1-ksfxEDxXX8HGwiWvYzaLmgK6NO4WmO8g6l9PrZiyjBQ7ehAoiS63Yxk8R9iVWgsgoDdqW2cmjn55fURvOFIusfpUd0r6IjYBSQctbyrYFkI; _cfuvid=G6jGA0d5Se4ghygETAgNPPALR34SaJOHHv_mM2q2WB4-1763729504384-0.0.1.1-604800000
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '112'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: !!binary |
          H4sIAAAAAAAAAwAAAP//jFLBTuMwFLznK4zPDUpC0kJviCPtSgjtSiuEolf7JTU4tmW/LLtC/feV
          k9KEXZC45PDmzWRm/F4TxriSfM242AOJzun0Bm/7THz/Vu7caivvfohw1/3cVjdFdS+v+SIy7O4J
          Bb2xzoXtnEZS1oyw8AiEUTVfLS9WxVWVlQPQWYk60lpHaXmepwaMTYusqNKsTPPySN9bJTDwNXtI
          GGPsdfhGo0bib75m2eJt0mEI0CJfn5YY497qOOEQggoEhvhiAoU1hGbwvlGEm82WBfIInTIte7H+
          OZzN1z02fYDo2fRazwAwxhLEzIPRxyNyOFnTtnXe7sI/VN4oo8K+9gjBmmgjkHV8QA8JY49DBf27
          VNx52zmqyT7j8Lv8cpTjU/MTuDxiZAn0NC7KxQditUQCpcOsQS5A7FFOzKlu6KWyMyCZRf7fy0fa
          Y2xl2q/IT4AQ6Ahl7TxKJd7nndY8xrP8bO1U8WCYB/S/lMCaFPr4DBIb6PV4Kzz8CYRd3SjTonde
          jQfTuDqHq9WuAlgKnhySvwAAAP//AwDhN9RTPwMAAA==
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a2051fb1fb30686-FRA
        Connection:
          - keep-alive
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json
        Date:
          - Fri, 21 Nov 2025 12:51:45 GMT
        Server:
          - cloudflare
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '343'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '379'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_33c88bf983c346a1a25349400506e277
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano"}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '112'
        content-type:
          - application/json
        cookie:
          - __cf_bm=KKuUVoq9Ic02.CdjaNifcZ8Ggd2pK2wENnupadYC0is-1763729504-1.0.1.1-ksfxEDxXX8HGwiWvYzaLmgK6NO4WmO8g6l9PrZiyjBQ7ehAoiS63Yxk8R9iVWgsgoDdqW2cmjn55fURvOFIusfpUd0r6IjYBSQctbyrYFkI; _cfuvid=G6jGA0d5Se4ghygETAgNPPALR34SaJOHHv_mM2q2WB4-1763729504384-0.0.1.1-604800000
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a2051fb1fb30686-FRA
        Connection:
          - keep-alive
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json
        Date:
          - Fri, 21 Nov 2025 12:51:45 GMT
        Server:
          - cloudflare
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '343'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '379'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_33c88bf983c346a1a25349400506e277
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: 'data: {"id":"chatcmpl-CeZmqFEds0jjF9AMBtDCpZv4tfa9l","object":"chat.completion.chunk","created":1763786720,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"role":"assistant","content":"","refusal":null},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"2gNA8Quf"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeZmqFEds0jjF9AMBtDCpZv4tfa9l","object":"chat.completion.chunk","created":1763786720,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"Lite"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"q3abEA"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeZmqFEds0jjF9AMBtDCpZv4tfa9l","object":"chat.completion.chunk","created":1763786720,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"LL"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"xnRxK9nI"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeZmqFEds0jjF9AMBtDCpZv4tfa9l","object":"chat.completion.chunk","created":1763786720,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"M"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"2KqkkjnAC"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeZmqFEds0jjF9AMBtDCpZv4tfa9l","object":"chat.completion.chunk","created":1763786720,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" streaming"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":""} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeZmqFEds0jjF9AMBtDCpZv4tfa9l","object":"chat.completion.chunk","created":1763786720,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":" works"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"oye3"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeZmqFEds0jjF9AMBtDCpZv4tfa9l","object":"chat.completion.chunk","created":1763786720,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{"content":"!"},"logprobs":null,"finish_reason":null}],"usage":null,"obfuscation":"E2FLDOxdy"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeZmqFEds0jjF9AMBtDCpZv4tfa9l","object":"chat.completion.chunk","created":1763786720,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}],"usage":null,"obfuscation":"Q9hq"} #magic___^_^___line #magic___^_^___line data: {"id":"chatcmpl-CeZmqFEds0jjF9AMBtDCpZv4tfa9l","object":"chat.completion.chunk","created":1763786720,"model":"gpt-4.1-nano-2025-04-14","service_tier":"default","system_fingerprint":"fp_1a97b5aa6c","choices":[],"usage":{"prompt_tokens":18,"completion_tokens":6,"total_tokens":24,"prompt_tokens_details":{"cached_tokens":0,"audio_tokens":0},"completion_tokens_details":{"reasoning_tokens":0,"audio_tokens":0,"accepted_prediction_tokens":0,"rejected_prediction_tokens":0}},"obfuscation":"ZkhSOsmbmx"} #magic___^_^___line #magic___^_^___line data: [DONE] #magic___^_^___line #magic___^_^___line '
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a25c6dd1a2b5d98-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Sat, 22 Nov 2025 04:45:21 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=jW_XAVUJlqLRiAIQTMAL_KURa4_281UcFLafDO48gSs-1763786721-1.0.1.1-WAChvYt8cXAndeOyGo1vAk9hhuzqxjE_fmeg.6oHDiyd5BPnrwyjDR9Na2Shf9JRvuNAWV6wl52lPUHD0D8zwWnhVYPt1q4mYEnQ9vewI20; path=/; expires=Sat, 22-Nov-25 05:15:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=eIhSSPVya67pkcx5YZxcleNBFkIx5FtX2UCQwrGvB44-1763786721248-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '274'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '287'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_a038d34684154213b4c1bc25f18035fb
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano","stream":true,"stream_options":{"include_usage":true}}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '166'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a25c6dd1a2b5d98-FRA
        Connection:
          - keep-alive
        Content-Type:
          - text/event-stream; charset=utf-8
        Date:
          - Sat, 22 Nov 2025 04:45:21 GMT
        Server:
          - cloudflare
        Set-Cookie:
          - __cf_bm=jW_XAVUJlqLRiAIQTMAL_KURa4_281UcFLafDO48gSs-1763786721-1.0.1.1-WAChvYt8cXAndeOyGo1vAk9hhuzqxjE_fmeg.6oHDiyd5BPnrwyjDR9Na2Shf9JRvuNAWV6wl52lPUHD0D8zwWnhVYPt1q4mYEnQ9vewI20; path=/; expires=Sat, 22-Nov-25 05:15:21 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
          - _cfuvid=eIhSSPVya67pkcx5YZxcleNBFkIx5FtX2UCQwrGvB44-1763786721248-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '274'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '287'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_a038d34684154213b4c1bc25f18035fb
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano"}'
      headers:
        Cookie:
          - __cf_bm=jW_XAVUJlqLRiAIQTMAL_KURa4_281UcFLafDO48gSs-1763786721-1.0.1.1-WAChvYt8cXAndeOyGo1vAk9hhuzqxjE_fmeg.6oHDiyd5BPnrwyjDR9Na2Shf9JRvuNAWV6wl52lPUHD0D8zwWnhVYPt1q4mYEnQ9vewI20; _cfuvid=eIhSSPVya67pkcx5YZxcleNBFkIx5FtX2UCQwrGvB44-1763786721248-0.0.1.1-604800000
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '112'
        content-type:
          - application/json
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: !!binary |
          H4sIAAAAAAAAA4xSQW7bMBC86xUsz1ZgOYqd+lYUAXpw0V7aQ4tAWJMriQnFZchV4yDw3wtKjqW0
          KdCLDjs7o5nhPmdCSKPlVkjVAqvO2/wj/ugC8M3N5WP7/dvTw0F9+fT1UNwdHnblB7lIDNrfoeIX
          1oWizltkQ26EVUBgTKrFZn25uV5vVsUAdKTRJlrjOS8vityBo3y1XF3lyzIvyhO9JaMwyq34mQkh
          xPPwTUadxoPciuXiZdJhjNCg3J6XhJCBbJpIiNFEBsdyMYGKHKMbvO8M4273WUQOCJ1xjXikcB/f
          zdcD1n2E5Nn11s4AcI4YUubB6O0JOZ6tWWp8oH38gypr40xsq4AQySUbkcnLAT1mQtwOFfSvUkkf
          qPNcMd3j8LviepSTU/MTuD5hTAx2Gq/KxRtilUYGY+OsQalAtagn5lQ39NrQDMhmkf/28pb2GNu4
          5n/kJ0Ap9Iy68gG1Ua/zTmsB01n+a+1c8WBYRgy/jMKKDYb0DBpr6O14KzI+Rcauqo1rMPhgxoOp
          fVXA+83+CmCtZHbMfgMAAP//AwCPr6Q1PwMAAA==
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a25c6e04b965d98-FRA
        Connection:
          - keep-alive
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json
        Date:
          - Sat, 22 Nov 2025 04:45:21 GMT
        Server:
          - cloudflare
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '348'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '372'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_81450518d6144258b0ead0dd816f3939
      status:
        code: 200
        message: OK
  - request:
      body: '{"messages":[{"role":"user","content":"Reply with exactly: ''LiteLLM streaming works!''"}],"model":"gpt-4.1-nano"}'
      headers:
        accept:
          - application/json
        accept-encoding:
          - gzip, deflate
        connection:
          - keep-alive
        content-length:
          - '112'
        content-type:
          - application/json
        cookie:
          - __cf_bm=jW_XAVUJlqLRiAIQTMAL_KURa4_281UcFLafDO48gSs-1763786721-1.0.1.1-WAChvYt8cXAndeOyGo1vAk9hhuzqxjE_fmeg.6oHDiyd5BPnrwyjDR9Na2Shf9JRvuNAWV6wl52lPUHD0D8zwWnhVYPt1q4mYEnQ9vewI20; _cfuvid=eIhSSPVya67pkcx5YZxcleNBFkIx5FtX2UCQwrGvB44-1763786721248-0.0.1.1-604800000
        host:
          - api.openai.com
        user-agent:
          - AsyncOpenAI/Python 1.92.3
        x-stainless-arch:
          - arm64
        x-stainless-async:
          - async:asyncio
        x-stainless-lang:
          - python
        x-stainless-os:
          - Linux
        x-stainless-package-version:
          - 1.92.3
        x-stainless-raw-response:
          - 'true'
        x-stainless-read-timeout:
          - '600.0'
        x-stainless-retry-count:
          - '0'
        x-stainless-runtime:
          - CPython
        x-stainless-runtime-version:
          - 3.13.7
      method: POST
      uri: https://api.openai.com/v1/chat/completions
    response:
      body:
        string: ''
      headers:
        Access-Control-Expose-Headers:
          - X-Request-ID
        CF-RAY:
          - 9a25c6e04b965d98-FRA
        Connection:
          - keep-alive
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json
        Date:
          - Sat, 22 Nov 2025 04:45:21 GMT
        Server:
          - cloudflare
        Strict-Transport-Security:
          - max-age=31536000; includeSubDomains; preload
        Transfer-Encoding:
          - chunked
        X-Content-Type-Options:
          - nosniff
        alt-svc:
          - h3=":443"; ma=86400
        cf-cache-status:
          - DYNAMIC
        openai-organization:
          - REDACTED
        openai-processing-ms:
          - '348'
        openai-project:
          - proj_wvaoRBrBR9ayhT5aPMqWgDtI
        openai-version:
          - '2020-10-01'
        x-envoy-upstream-service-time:
          - '372'
        x-openai-proxy-wasm:
          - v0.1
        x-ratelimit-limit-requests:
          - '500'
        x-ratelimit-limit-tokens:
          - '200000'
        x-ratelimit-remaining-requests:
          - '499'
        x-ratelimit-remaining-tokens:
          - '199986'
        x-ratelimit-reset-requests:
          - 120ms
        x-ratelimit-reset-tokens:
          - 4ms
        x-request-id:
          - req_81450518d6144258b0ead0dd816f3939
      status:
        code: 200
        message: OK
>>>>>>> 45227dca (Refactor LLM layer to strict typing for Gemini thought signatures)
version: 1
