interactions:
  - request:
      body: '{"contents": [{"parts": [{"text": "Count to 5"}], "role": "user"}], "generationConfig": {}}'
      headers:
        Content-Type:
          - application/json
        user-agent:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
        x-goog-api-client:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
      method: post
      uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent
    response:
      body:
        string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\": [\n          {\n            \"text\": \"Here's counting to 5:\\n\\n1\\n2\\n3\\n4\\n5\"\n          }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"index\": 0\n    }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\": 5,\n    \"candidatesTokenCount\": 18,\n    \"totalTokenCount\": 23,\n    \"promptTokensDetails\": [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 5\n      }\n    ]\n  },\n  \"modelVersion\": \"gemini-3-flash-preview\",\n  \"responseId\": \"S_4eaZrBI9Dbxs0Pn6Wh8AI\"\n}\n"
      headers:
        Alt-Svc:
          - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json; charset=UTF-8
        Date:
          - Thu, 20 Nov 2025 11:40:59 GMT
        Server:
          - scaffolding on HTTPServer2
        Server-Timing:
          - gfet4t7; dur=579
        Transfer-Encoding:
          - chunked
        Vary:
          - Origin
          - X-Origin
          - Referer
        X-Content-Type-Options:
          - nosniff
        X-Frame-Options:
          - SAMEORIGIN
        X-XSS-Protection:
          - '0'
      status:
        code: 200
        message: OK
  - request:
      body: '{"contents": [{"parts": [{"text": "Count to 5"}], "role": "user"}], "generationConfig": {}}'
      headers:
        Content-Type:
          - application/json
        user-agent:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
        x-goog-api-client:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
      method: post
      uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent
    response:
      body:
        string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\": [\n          {\n            \"text\": \"Here you go:\\n\\n1\\n2\\n3\\n4\\n5\"\n          }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"index\": 0\n    }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\": 5,\n    \"candidatesTokenCount\": 14,\n    \"totalTokenCount\": 19,\n    \"promptTokensDetails\": [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 5\n      }\n    ]\n  },\n  \"modelVersion\": \"gemini-3-flash-preview\",\n  \"responseId\": \"0xMgaYisHt6nkdUPwZmXmQ8\"\n}\n"
      headers:
        Alt-Svc:
          - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json; charset=UTF-8
        Date:
          - Fri, 21 Nov 2025 07:25:07 GMT
        Server:
          - scaffolding on HTTPServer2
        Server-Timing:
          - gfet4t7; dur=303
        Transfer-Encoding:
          - chunked
        Vary:
          - Origin
          - X-Origin
          - Referer
        X-Content-Type-Options:
          - nosniff
        X-Frame-Options:
          - SAMEORIGIN
        X-XSS-Protection:
          - '0'
      status:
        code: 200
        message: OK
  - request:
      body: '{"contents": [{"parts": [{"text": "Count to 5"}], "role": "user"}], "generationConfig": {}}'
      headers:
        Content-Type:
          - application/json
        user-agent:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
        x-goog-api-client:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
      method: post
      uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent
    response:
      body:
        string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\": [\n          {\n            \"text\": \"1, 2, 3, 4, 5\"\n          }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"index\": 0\n    }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\": 5,\n    \"candidatesTokenCount\": 13,\n    \"totalTokenCount\": 18,\n    \"promptTokensDetails\": [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 5\n      }\n    ]\n  },\n  \"modelVersion\": \"gemini-3-flash-preview\",\n  \"responseId\": \"HhQgabvSMMqqxN8P5ffvMQ\"\n}\n"
      headers:
        Alt-Svc:
          - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json; charset=UTF-8
        Date:
          - Fri, 21 Nov 2025 07:26:22 GMT
        Server:
          - scaffolding on HTTPServer2
        Server-Timing:
          - gfet4t7; dur=301
        Transfer-Encoding:
          - chunked
        Vary:
          - Origin
          - X-Origin
          - Referer
        X-Content-Type-Options:
          - nosniff
        X-Frame-Options:
          - SAMEORIGIN
        X-XSS-Protection:
          - '0'
      status:
        code: 200
        message: OK
  - request:
      body: '{"contents": [{"parts": [{"text": "Count to 5"}], "role": "user"}], "generationConfig": {}}'
      headers:
        Content-Type:
          - application/json
        user-agent:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
        x-goog-api-client:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
      method: post
      uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent
    response:
      body:
        string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\": [\n          {\n            \"text\": \"Here's counting to 5:\\n\\n1\\n2\\n3\\n4\\n5\"\n          }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"index\": 0\n    }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\": 5,\n    \"candidatesTokenCount\": 18,\n    \"totalTokenCount\": 23,\n    \"promptTokensDetails\": [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 5\n      }\n    ]\n  },\n  \"modelVersion\": \"gemini-3-flash-preview\",\n  \"responseId\": \"ylQgaeCDJfWT28oPs5HAmQs\"\n}\n"
      headers:
        Alt-Svc:
          - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json; charset=UTF-8
        Date:
          - Fri, 21 Nov 2025 12:02:18 GMT
        Server:
          - scaffolding on HTTPServer2
        Server-Timing:
          - gfet4t7; dur=609
        Transfer-Encoding:
          - chunked
        Vary:
          - Origin
          - X-Origin
          - Referer
        X-Content-Type-Options:
          - nosniff
        X-Frame-Options:
          - SAMEORIGIN
        X-XSS-Protection:
          - '0'
      status:
        code: 200
        message: OK
  - request:
      body: '{"contents": [{"parts": [{"text": "Count to 5"}], "role": "user"}], "generationConfig": {}}'
      headers:
        Content-Type:
          - application/json
        user-agent:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
        x-goog-api-client:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
      method: post
      uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent
    response:
      body:
        string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\": [\n          {\n            \"text\": \"1\\n2\\n3\\n4\\n5\"\n          }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"index\": 0\n    }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\": 5,\n    \"candidatesTokenCount\": 9,\n    \"totalTokenCount\": 14,\n    \"promptTokensDetails\": [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 5\n      }\n    ]\n  },\n  \"modelVersion\": \"gemini-3-flash-preview\",\n  \"responseId\": \"WWAgac3DI4SensEPkoOA0Qw\"\n}\n"
      headers:
        Alt-Svc:
          - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json; charset=UTF-8
        Date:
          - Fri, 21 Nov 2025 12:51:37 GMT
        Server:
          - scaffolding on HTTPServer2
        Server-Timing:
          - gfet4t7; dur=293
        Transfer-Encoding:
          - chunked
        Vary:
          - Origin
          - X-Origin
          - Referer
        X-Content-Type-Options:
          - nosniff
        X-Frame-Options:
          - SAMEORIGIN
        X-XSS-Protection:
          - '0'
      status:
        code: 200
        message: OK
  - request:
      body: '{"contents": [{"parts": [{"text": "Count to 5"}], "role": "user"}], "generationConfig": {}}'
      headers:
        Content-Type:
          - application/json
        user-agent:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
        x-goog-api-client:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
      method: post
      uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent
    response:
      body:
        string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\": [\n          {\n            \"text\": \"Here's the count to 5:\\n\\n1\\n2\\n3\\n4\\n5\"\n          }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"index\": 0\n    }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\": 5,\n    \"candidatesTokenCount\": 19,\n    \"totalTokenCount\": 24,\n    \"promptTokensDetails\": [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 5\n      }\n    ]\n  },\n  \"modelVersion\": \"gemini-3-flash-preview\",\n  \"responseId\": \"3T8hacrXG-X4kdUPw_Lp0Aw\"\n}\n"
      headers:
        Alt-Svc:
          - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json; charset=UTF-8
        Date:
          - Sat, 22 Nov 2025 04:45:17 GMT
        Server:
          - scaffolding on HTTPServer2
        Server-Timing:
          - gfet4t7; dur=280
        Transfer-Encoding:
          - chunked
        Vary:
          - Origin
          - X-Origin
          - Referer
        X-Content-Type-Options:
          - nosniff
        X-Frame-Options:
          - SAMEORIGIN
        X-XSS-Protection:
          - '0'
      status:
        code: 200
        message: OK
  - request:
      body: '{"contents": [{"parts": [{"text": "Count to 5"}], "role": "user"}], "generationConfig": {}}'
      headers:
        Content-Type:
          - application/json
        user-agent:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
        x-goog-api-client:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
      method: post
      uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent
    response:
      body:
        string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\": [\n          {\n            \"text\": \"1, 2, 3, 4, 5\"\n          }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"index\": 0\n    }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\": 5,\n    \"candidatesTokenCount\": 13,\n    \"totalTokenCount\": 18,\n    \"promptTokensDetails\": [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 5\n      }\n    ]\n  },\n  \"modelVersion\": \"gemini-3-flash-preview\",\n  \"responseId\": \"_uUiafL9I73jnsEPlJujgQ4\"\n}\n"
      headers:
        Alt-Svc:
          - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json; charset=UTF-8
        Date:
          - Sun, 23 Nov 2025 10:46:22 GMT
        Server:
          - scaffolding on HTTPServer2
        Server-Timing:
          - gfet4t7; dur=332
        Transfer-Encoding:
          - chunked
        Vary:
          - Origin
          - X-Origin
          - Referer
        X-Content-Type-Options:
          - nosniff
        X-Frame-Options:
          - SAMEORIGIN
        X-XSS-Protection:
          - '0'
      status:
        code: 200
        message: OK
  - request:
      body: '{"contents": [{"parts": [{"text": "Count to 5"}], "role": "user"}], "generationConfig": {}}'
      headers:
        Content-Type:
          - application/json
        user-agent:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
        x-goog-api-client:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
      method: post
      uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent
    response:
      body:
        string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\": [\n          {\n            \"text\": \"Okay, here we go!\\n\\n1\\n2\\n3\\n4\\n5\"\n          }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"index\": 0\n    }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\": 5,\n    \"candidatesTokenCount\": 16,\n    \"totalTokenCount\": 21,\n    \"promptTokensDetails\": [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 5\n      }\n    ]\n  },\n  \"modelVersion\": \"gemini-3-flash-preview\",\n  \"responseId\": \"6-giaZbQB6TCvdIPmoCPuQ8\"\n}\n"
      headers:
        Alt-Svc:
          - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json; charset=UTF-8
        Date:
          - Sun, 23 Nov 2025 10:58:51 GMT
        Server:
          - scaffolding on HTTPServer2
        Server-Timing:
          - gfet4t7; dur=325
        Transfer-Encoding:
          - chunked
        Vary:
          - Origin
          - X-Origin
          - Referer
        X-Content-Type-Options:
          - nosniff
        X-Frame-Options:
          - SAMEORIGIN
        X-XSS-Protection:
          - '0'
      status:
        code: 200
        message: OK
  - request:
      body: '{"contents": [{"parts": [{"text": "Count to 5"}], "role": "user"}], "generationConfig": {}}'
      headers:
        Content-Type:
          - application/json
        user-agent:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
        x-goog-api-client:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
      method: post
      uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent
    response:
      body:
        string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\": [\n          {\n            \"text\": \"1, 2, 3, 4, 5\"\n          }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"index\": 0\n    }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\": 5,\n    \"candidatesTokenCount\": 13,\n    \"totalTokenCount\": 18,\n    \"promptTokensDetails\": [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 5\n      }\n    ]\n  },\n  \"modelVersion\": \"gemini-3-flash-preview\",\n  \"responseId\": \"EvEiaeOtLYzlvdIPrIfP6Q0\"\n}\n"
      headers:
        Alt-Svc:
          - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json; charset=UTF-8
        Date:
          - Sun, 23 Nov 2025 11:33:38 GMT
        Server:
          - scaffolding on HTTPServer2
        Server-Timing:
          - gfet4t7; dur=375
        Transfer-Encoding:
          - chunked
        Vary:
          - Origin
          - X-Origin
          - Referer
        X-Content-Type-Options:
          - nosniff
        X-Frame-Options:
          - SAMEORIGIN
        X-XSS-Protection:
          - '0'
      status:
        code: 200
        message: OK
  - request:
      body: '{"contents": [{"parts": [{"text": "Count to 5"}], "role": "user"}], "generationConfig": {}}'
      headers:
        Content-Type:
          - application/json
        user-agent:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
        x-goog-api-client:
          - google-genai-sdk/1.38.0 gl-python/3.13.7
      method: post
      uri: https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent
    response:
      body:
        string: "{\n  \"candidates\": [\n    {\n      \"content\": {\n        \"parts\": [\n          {\n            \"text\": \"1, 2, 3, 4, 5\"\n          }\n        ],\n        \"role\": \"model\"\n      },\n      \"finishReason\": \"STOP\",\n      \"index\": 0\n    }\n  ],\n  \"usageMetadata\": {\n    \"promptTokenCount\": 5,\n    \"candidatesTokenCount\": 13,\n    \"totalTokenCount\": 18,\n    \"promptTokensDetails\": [\n      {\n        \"modality\": \"TEXT\",\n        \"tokenCount\": 5\n      }\n    ]\n  },\n  \"modelVersion\": \"gemini-3-flash-preview\",\n  \"responseId\": \"l_Qiac_sMJzqkdUP3MHd6Q0\"\n}\n"
      headers:
        Alt-Svc:
          - h3=":443"; ma=2592000,h3-29=":443"; ma=2592000
        Content-Encoding:
          - gzip
        Content-Type:
          - application/json; charset=UTF-8
        Date:
          - Sun, 23 Nov 2025 11:48:39 GMT
        Server:
          - scaffolding on HTTPServer2
        Server-Timing:
          - gfet4t7; dur=369
        Transfer-Encoding:
          - chunked
        Vary:
          - Origin
          - X-Origin
          - Referer
        X-Content-Type-Options:
          - nosniff
        X-Frame-Options:
          - SAMEORIGIN
        X-XSS-Protection:
          - '0'
      status:
        code: 200
        message: OK
version: 1
